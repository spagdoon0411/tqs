{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from optimizer_supervised import Optimizer\n",
    "from Ising import Ising\n",
    "from model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_setup():\n",
    "    # Setup for PyTorch:\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = torch.device(\"cuda\")\n",
    "        print(\"PyTorch is using GPU {}\".format(torch.cuda.current_device()))\n",
    "    else:\n",
    "        torch_device = torch.device(\"cpu\")\n",
    "        print(\"GPU unavailable; using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using GPU 0\n"
     ]
    }
   ],
   "source": [
    "gpu_setup()\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [ 8],\n",
       "        [10],\n",
       "        [12],\n",
       "        [14],\n",
       "        [16],\n",
       "        [18],\n",
       "        [20]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_sizes = torch.arange(2, 21, 2, device=\"cpu\").reshape(-1, 1)\n",
    "system_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580740865/work/aten/src/ATen/native/TensorShape.cpp:3675.)\n",
      "  return func(*args, **kwargs)\n",
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 1000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Small allocation for model parameters, layers, etc.\n",
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): TQSPositionalEncoding1D(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_Q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_K): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (linear_V): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (amp_head): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (phase_head): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(testmodel, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following .forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16])\n"
     ]
    }
   ],
   "source": [
    "H = Hamiltonians[7]\n",
    "print(H.system_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spins = H.basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.set_param(system_size=H.system_size, param=torch.tensor([1.0], device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.5700, -0.8337],\n",
       "          [-0.5700, -0.8337],\n",
       "          [-0.5700, -0.8337],\n",
       "          ...,\n",
       "          [-0.5700, -0.8337],\n",
       "          [-0.5700, -0.8337],\n",
       "          [-0.5700, -0.8337]],\n",
       " \n",
       "         [[-0.5593, -0.8477],\n",
       "          [-0.5593, -0.8477],\n",
       "          [-0.5593, -0.8477],\n",
       "          ...,\n",
       "          [-0.4986, -0.9349],\n",
       "          [-0.4986, -0.9349],\n",
       "          [-0.4986, -0.9349]],\n",
       " \n",
       "         [[-0.5328, -0.8842],\n",
       "          [-0.5328, -0.8842],\n",
       "          [-0.5328, -0.8842],\n",
       "          ...,\n",
       "          [-0.4639, -0.9911],\n",
       "          [-0.4639, -0.9911],\n",
       "          [-0.4639, -0.9911]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.5647, -0.8406],\n",
       "          [-0.5647, -0.8406],\n",
       "          [-0.5647, -0.8406],\n",
       "          ...,\n",
       "          [-0.5110, -0.9161],\n",
       "          [-0.5110, -0.9161],\n",
       "          [-0.5110, -0.9161]],\n",
       " \n",
       "         [[-0.5470, -0.8644],\n",
       "          [-0.5470, -0.8644],\n",
       "          [-0.5173, -0.9067],\n",
       "          ...,\n",
       "          [-0.5224, -0.8992],\n",
       "          [-0.4894, -0.9493],\n",
       "          [-0.4894, -0.9493]],\n",
       " \n",
       "         [[-0.5271, -0.8924],\n",
       "          [-0.5048, -0.9254],\n",
       "          [-0.5267, -0.8929],\n",
       "          ...,\n",
       "          [-0.4776, -0.9683],\n",
       "          [-0.4873, -0.9527],\n",
       "          [-0.4811, -0.9626]]], device='cuda:0', grad_fn=<CatBackward0>),\n",
       " tensor([[[5.3967, 6.0806],\n",
       "          [5.3967, 6.0806],\n",
       "          [5.3967, 6.0806],\n",
       "          ...,\n",
       "          [5.3967, 6.0806],\n",
       "          [5.3967, 6.0806],\n",
       "          [5.3967, 6.0806]],\n",
       " \n",
       "         [[5.7025, 6.6401],\n",
       "          [5.7025, 6.6401],\n",
       "          [5.7025, 6.6401],\n",
       "          ...,\n",
       "          [4.3881, 5.8754],\n",
       "          [4.3881, 5.8754],\n",
       "          [4.3881, 5.8754]],\n",
       " \n",
       "         [[6.1896, 6.7839],\n",
       "          [6.1896, 6.7839],\n",
       "          [6.1896, 6.7839],\n",
       "          ...,\n",
       "          [4.4899, 6.2195],\n",
       "          [4.4899, 6.2195],\n",
       "          [4.4899, 6.2195]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[6.9809, 7.0698],\n",
       "          [6.9809, 7.0698],\n",
       "          [6.9809, 7.0698],\n",
       "          ...,\n",
       "          [4.5505, 6.6885],\n",
       "          [4.5505, 6.6885],\n",
       "          [4.5505, 6.6885]],\n",
       " \n",
       "         [[7.0818, 6.8991],\n",
       "          [7.0818, 6.8991],\n",
       "          [6.2626, 6.4902],\n",
       "          ...,\n",
       "          [5.8242, 6.8548],\n",
       "          [4.6022, 6.5184],\n",
       "          [4.6022, 6.5184]],\n",
       " \n",
       "         [[7.0004, 6.7663],\n",
       "          [6.1956, 6.3514],\n",
       "          [6.9740, 6.7380],\n",
       "          ...,\n",
       "          [4.6612, 6.3183],\n",
       "          [5.6430, 6.5521],\n",
       "          [4.5805, 6.3267]]], device='cuda:0', grad_fn=<CatBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = testmodel.forward(spins)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del testmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = testmodel.wrap_spins(spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel.src_mask = testmodel._generate_square_subsequent_mask(src.size(0)).to(\n",
    "    src.device\n",
    ")\n",
    "testmodel.src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7726], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_size = src[\n",
    "    : testmodel.n_dim, 0, testmodel.phys_dim : testmodel.phys_dim + testmodel.n_dim\n",
    "].diag()\n",
    "system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_size = system_size.exp().round().to(torch.int64)\n",
    "system_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         ...,\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698],\n",
       "         [-1.4493,  1.2511,  0.7615,  ..., -0.6516, -1.4590, -0.8698]],\n",
       "\n",
       "        [[-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         ...,\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424],\n",
       "         [-0.0892, -0.2254,  0.2675,  ..., -0.2129,  0.3032, -0.1424]],\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         ...,\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         ...,\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]],\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         ...,\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]],\n",
       "\n",
       "        [[ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         ...,\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067],\n",
       "         [ 0.1982, -0.0404, -0.3834,  ..., -0.1147, -0.5085,  0.5536],\n",
       "         [ 0.4225, -0.5073, -0.4767,  ..., -0.4371,  0.2144, -0.1067]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = testmodel.encoder(src) * math.sqrt(testmodel.embedding_size)\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a problem if GPU memory usage increases at this point; this operation should be in-place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         ...,\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660],\n",
       "         [-1.4560,  1.2795,  0.7603,  ..., -0.6402, -1.4689, -0.8660]],\n",
       "\n",
       "        [[-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         ...,\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544],\n",
       "         [-0.1021, -0.2299,  0.2635,  ..., -0.2287,  0.3352, -0.1544]],\n",
       "\n",
       "        [[ 0.1982,  0.9596, -0.3834,  ...,  0.8853, -0.5085,  1.5536],\n",
       "         [ 0.1982,  0.9596, -0.3834,  ...,  0.8853, -0.5085,  1.5536],\n",
       "         [ 0.1982,  0.9596, -0.3834,  ...,  0.8853, -0.5085,  1.5536],\n",
       "         ...,\n",
       "         [ 0.4225,  0.4927, -0.4767,  ...,  0.5629,  0.2144,  0.8933],\n",
       "         [ 0.4225,  0.4927, -0.4767,  ...,  0.5629,  0.2144,  0.8933],\n",
       "         [ 0.4225,  0.4927, -0.4767,  ...,  0.5629,  0.2144,  0.8933]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.6183,  0.8671,  0.4724,  ...,  0.8853, -0.5062,  1.5536],\n",
       "         [ 0.6183,  0.8671,  0.4724,  ...,  0.8853, -0.5062,  1.5536],\n",
       "         [ 0.6183,  0.8671,  0.4724,  ...,  0.8853, -0.5062,  1.5536],\n",
       "         ...,\n",
       "         [ 0.8427,  0.4001,  0.3792,  ...,  0.5629,  0.2167,  0.8933],\n",
       "         [ 0.8427,  0.4001,  0.3792,  ...,  0.5629,  0.2167,  0.8933],\n",
       "         [ 0.8427,  0.4001,  0.3792,  ...,  0.5629,  0.2167,  0.8933]],\n",
       "\n",
       "        [[ 1.1888,  0.0964,  0.6164,  ...,  0.8853, -0.5060,  1.5536],\n",
       "         [ 1.1888,  0.0964,  0.6164,  ...,  0.8853, -0.5060,  1.5536],\n",
       "         [ 1.4131, -0.3706,  0.5232,  ...,  0.5629,  0.2169,  0.8933],\n",
       "         ...,\n",
       "         [ 1.1888,  0.0964,  0.6164,  ...,  0.8853, -0.5060,  1.5536],\n",
       "         [ 1.4131, -0.3706,  0.5232,  ...,  0.5629,  0.2169,  0.8933],\n",
       "         [ 1.4131, -0.3706,  0.5232,  ...,  0.5629,  0.2169,  0.8933]],\n",
       "\n",
       "        [[ 0.8485, -0.8001,  0.4524,  ...,  0.8853, -0.5058,  1.5536],\n",
       "         [ 1.0728, -1.2670,  0.3592,  ...,  0.5629,  0.2170,  0.8933],\n",
       "         [ 0.8485, -0.8001,  0.4524,  ...,  0.8853, -0.5058,  1.5536],\n",
       "         ...,\n",
       "         [ 1.0728, -1.2670,  0.3592,  ...,  0.5629,  0.2170,  0.8933],\n",
       "         [ 0.8485, -0.8001,  0.4524,  ...,  0.8853, -0.5058,  1.5536],\n",
       "         [ 1.0728, -1.2670,  0.3592,  ...,  0.5629,  0.2170,  0.8933]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = testmodel.pos_encoder(src)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         ...,\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149],\n",
       "         [ 1.3218, -0.5965, -1.0745,  ...,  0.3264, -0.4246, -1.3149]],\n",
       "\n",
       "        [[ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         ...,\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868],\n",
       "         [ 0.9145, -0.9515, -0.9850,  ..., -0.0988, -0.5072, -0.3868]],\n",
       "\n",
       "        [[ 0.3780, -1.1240, -1.0349,  ..., -0.2109, -0.7638,  1.0329],\n",
       "         [ 0.3780, -1.1240, -1.0349,  ..., -0.2109, -0.7638,  1.0329],\n",
       "         [ 0.3780, -1.1240, -1.0349,  ..., -0.2109, -0.7638,  1.0329],\n",
       "         ...,\n",
       "         [ 0.4098, -1.3203, -0.6677,  ...,  0.0847, -0.5992,  0.0962],\n",
       "         [ 0.4098, -1.3203, -0.6677,  ...,  0.0847, -0.5992,  0.0962],\n",
       "         [ 0.4098, -1.3203, -0.6677,  ...,  0.0847, -0.5992,  0.0962]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3596, -1.2878, -0.4460,  ..., -0.3784, -0.2723,  1.3588],\n",
       "         [-0.3596, -1.2878, -0.4460,  ..., -0.3784, -0.2723,  1.3588],\n",
       "         [-0.3596, -1.2878, -0.4460,  ..., -0.3784, -0.2723,  1.3588],\n",
       "         ...,\n",
       "         [-0.1743, -1.3408, -0.4427,  ..., -0.4676, -0.3131,  0.4132],\n",
       "         [-0.1743, -1.3408, -0.4427,  ..., -0.4676, -0.3131,  0.4132],\n",
       "         [-0.1743, -1.3408, -0.4427,  ..., -0.4676, -0.3131,  0.4132]],\n",
       "\n",
       "        [[-0.2757, -1.3132, -0.3750,  ..., -0.3658, -0.2897,  1.2813],\n",
       "         [-0.2757, -1.3132, -0.3750,  ..., -0.3658, -0.2897,  1.2813],\n",
       "         [-0.4871, -1.6481, -0.0597,  ..., -0.1524, -0.1294,  0.8363],\n",
       "         ...,\n",
       "         [-0.0593, -1.1778, -0.5836,  ..., -0.5776, -0.3883,  0.6502],\n",
       "         [-0.1138, -1.3405, -0.4261,  ..., -0.4941, -0.3199,  0.4176],\n",
       "         [-0.1138, -1.3405, -0.4261,  ..., -0.4941, -0.3199,  0.4176]],\n",
       "\n",
       "        [[-0.3291, -1.4244, -0.3467,  ..., -0.3208, -0.2922,  1.2279],\n",
       "         [-0.5741, -1.7603, -0.0492,  ..., -0.1247, -0.1376,  0.8103],\n",
       "         [-0.3373, -1.4102, -0.3645,  ..., -0.3412, -0.2937,  1.2181],\n",
       "         ...,\n",
       "         [-0.1875, -1.3956, -0.4357,  ..., -0.4924, -0.3626,  0.4625],\n",
       "         [-0.1227, -1.2308, -0.5920,  ..., -0.5779, -0.4126,  0.6528],\n",
       "         [-0.1790, -1.3914, -0.4386,  ..., -0.5024, -0.3532,  0.4388]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = testmodel.transformer_encoder(src, testmodel.src_mask)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
