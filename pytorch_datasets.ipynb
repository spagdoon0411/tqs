{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading Methods in PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to explore PyTorch's tools for lazily loading datasets from disk instead of storing the datasets in memory. During supervised training over large parameter spaces, it'll be important to store many ground states for many parameter configurations before computation, as calculating them on the fly becomes time-consuming.\n",
    "\n",
    "The goal is a tool living in the CPU that loads relevant data from disk (possibly without order, like random-access memory) to feed it to the model on the GPU. **As the model is training on that data on the GPU, the CPU should fetch the next batch of data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from Hamiltonian import Ising, XYZ\n",
    "from optimizer_supervised import Optimizer\n",
    "from model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.657965112114926\n",
      "tensor([-0.5694,  0.2421,  0.2421, -0.2421,  0.2421, -0.2421, -0.2421,  0.5694],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csmuser\\Desktop\\Spandan_Suthar_Research\\tqs\\Hamiltonian_utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  system_size = torch.tensor(system_size, dtype=torch.int64).reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "iham = Ising(3)\n",
    "energy, psi = iham.calc_ground(param=torch.tensor([1.3]))\n",
    "print(energy)\n",
    "print(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.7620871035666354\n",
      "tensor([-1.2634e-17-4.2907e-18j,  2.0638e-02-1.3801e-02j,\n",
      "        -1.4873e-02-1.4024e-02j, -1.0300e-17+1.0365e-16j,\n",
      "        -2.9830e-02+5.1339e-03j, -1.4745e-16-9.8012e-17j,\n",
      "         1.2490e-16+5.0307e-17j,  1.4131e-01+1.3325e-01j,\n",
      "        -3.5634e-03+1.7197e-02j,  2.1684e-16-9.3675e-17j,\n",
      "        -2.2204e-16+1.8908e-16j,  5.4781e-02-2.6438e-01j,\n",
      "         8.8471e-17-1.1449e-16j, -3.1728e-01+2.1217e-01j,\n",
      "         2.8342e-01-4.8779e-02j,  1.0408e-17+1.8735e-16j,\n",
      "         2.7628e-02+5.4945e-03j, -8.0448e-17+8.5869e-17j,\n",
      "         5.0524e-17-1.5005e-16j, -1.9609e-01+1.3113e-01j,\n",
      "         4.5970e-17+9.5193e-17j,  4.5859e-01-7.8925e-02j,\n",
      "        -4.2473e-01-8.4469e-02j, -1.1449e-16-7.2858e-17j,\n",
      "        -1.0582e-16+4.5103e-17j, -2.6250e-01-5.2205e-02j,\n",
      "         2.2864e-01+2.1560e-01j,  1.6653e-16-1.5266e-16j,\n",
      "         3.3856e-02-1.6339e-01j, -1.3184e-16+1.8041e-16j,\n",
      "         1.4658e-16-1.8041e-16j, -4.0742e-16-3.0910e-16j],\n",
      "       dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "hham = XYZ(5)\n",
    "energy, psi = hham.calc_ground(param=torch.tensor([0.5, 0, 0.2]))\n",
    "print(energy)\n",
    "print(psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are from optimization_tests.ipynb (or optimizer_supervised.py):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parameter_range(start, end, step):\n",
    "    \"\"\"\n",
    "    A simple generator returning the next value in a range of values\n",
    "    whenever called, according to a step size.\n",
    "    \"\"\"\n",
    "    value = start\n",
    "    while value < end:\n",
    "        yield value\n",
    "        value += step\n",
    "\n",
    "\n",
    "def generate_parameter_points(parameter_ranges, step_sizes, distribution=None):\n",
    "    \"\"\"\n",
    "    Generate all possible combinations of parameter values for a model\n",
    "    (i.e., the Cartesian product of values of parameters in a slice of parameter space)\n",
    "\n",
    "    Parameters:\n",
    "        parameter_ranges: torch.Tensor of shape (2, n_parameters)\n",
    "            The starting and ending values for each dimension of the slice of parameter space\n",
    "        step_sizes: torch.Tensor of shape (n_parameters,)\n",
    "            The step size for each dimension of the slice of parameter space\n",
    "        distribution: N/A\n",
    "            TODO: Not implemented\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    parameter_ranges = parameter_ranges.T  # TODO: remove\n",
    "\n",
    "    if distribution is not None:\n",
    "        raise NotImplementedError(\n",
    "            \"Sampling using a custom distribution is not implemented yet.\"\n",
    "        )\n",
    "\n",
    "    # Every possible individual parameter value for each parameter, in order\n",
    "    parameter_ranges = [\n",
    "        generate_parameter_range(start.item(), end.item(), step.item())\n",
    "        for (start, end), step in zip(parameter_ranges, step_sizes)\n",
    "    ]\n",
    "\n",
    "    return itertools.product(*parameter_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -1.0000,  0.2000],\n",
      "        [ 1.0000,  1.0000,  0.3000]])\n",
      "tensor([0.1000, 0.1000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "param_ranges = torch.tensor([[0, -1, 0.2], [1, 1, 0.3]])\n",
    "param_steps = torch.tensor([0.1, 0.1, 0.1])\n",
    "\n",
    "print(param_ranges)\n",
    "print(param_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_generator = generate_parameter_points(param_ranges, param_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -1.0000,  0.2000])\n",
      "tensor([ 0.0000, -1.0000,  0.3000])\n",
      "tensor([ 0.0000, -0.9000,  0.2000])\n",
      "tensor([ 0.0000, -0.9000,  0.3000])\n",
      "tensor([ 0.0000, -0.8000,  0.2000])\n",
      "tensor([ 0.0000, -0.8000,  0.3000])\n",
      "tensor([ 0.0000, -0.7000,  0.2000])\n",
      "tensor([ 0.0000, -0.7000,  0.3000])\n",
      "tensor([ 0.0000, -0.6000,  0.2000])\n",
      "tensor([ 0.0000, -0.6000,  0.3000])\n",
      "tensor([ 0.0000, -0.5000,  0.2000])\n",
      "tensor([ 0.0000, -0.5000,  0.3000])\n",
      "tensor([ 0.0000, -0.4000,  0.2000])\n",
      "tensor([ 0.0000, -0.4000,  0.3000])\n",
      "tensor([ 0.0000, -0.3000,  0.2000])\n",
      "tensor([ 0.0000, -0.3000,  0.3000])\n",
      "tensor([ 0.0000, -0.2000,  0.2000])\n",
      "tensor([ 0.0000, -0.2000,  0.3000])\n",
      "tensor([ 0.0000, -0.1000,  0.2000])\n",
      "tensor([ 0.0000, -0.1000,  0.3000])\n",
      "tensor([0.0000e+00, 1.4901e-08, 2.0000e-01])\n",
      "tensor([0.0000e+00, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.0000, 0.1000, 0.2000])\n",
      "tensor([0.0000, 0.1000, 0.3000])\n",
      "tensor([0.0000, 0.2000, 0.2000])\n",
      "tensor([0.0000, 0.2000, 0.3000])\n",
      "tensor([0.0000, 0.3000, 0.2000])\n",
      "tensor([0.0000, 0.3000, 0.3000])\n",
      "tensor([0.0000, 0.4000, 0.2000])\n",
      "tensor([0.0000, 0.4000, 0.3000])\n",
      "tensor([0.0000, 0.5000, 0.2000])\n",
      "tensor([0.0000, 0.5000, 0.3000])\n",
      "tensor([0.0000, 0.6000, 0.2000])\n",
      "tensor([0.0000, 0.6000, 0.3000])\n",
      "tensor([0.0000, 0.7000, 0.2000])\n",
      "tensor([0.0000, 0.7000, 0.3000])\n",
      "tensor([0.0000, 0.8000, 0.2000])\n",
      "tensor([0.0000, 0.8000, 0.3000])\n",
      "tensor([0.0000, 0.9000, 0.2000])\n",
      "tensor([0.0000, 0.9000, 0.3000])\n",
      "tensor([ 0.1000, -1.0000,  0.2000])\n",
      "tensor([ 0.1000, -1.0000,  0.3000])\n",
      "tensor([ 0.1000, -0.9000,  0.2000])\n",
      "tensor([ 0.1000, -0.9000,  0.3000])\n",
      "tensor([ 0.1000, -0.8000,  0.2000])\n",
      "tensor([ 0.1000, -0.8000,  0.3000])\n",
      "tensor([ 0.1000, -0.7000,  0.2000])\n",
      "tensor([ 0.1000, -0.7000,  0.3000])\n",
      "tensor([ 0.1000, -0.6000,  0.2000])\n",
      "tensor([ 0.1000, -0.6000,  0.3000])\n",
      "tensor([ 0.1000, -0.5000,  0.2000])\n",
      "tensor([ 0.1000, -0.5000,  0.3000])\n",
      "tensor([ 0.1000, -0.4000,  0.2000])\n",
      "tensor([ 0.1000, -0.4000,  0.3000])\n",
      "tensor([ 0.1000, -0.3000,  0.2000])\n",
      "tensor([ 0.1000, -0.3000,  0.3000])\n",
      "tensor([ 0.1000, -0.2000,  0.2000])\n",
      "tensor([ 0.1000, -0.2000,  0.3000])\n",
      "tensor([ 0.1000, -0.1000,  0.2000])\n",
      "tensor([ 0.1000, -0.1000,  0.3000])\n",
      "tensor([1.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([1.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.1000, 0.1000, 0.2000])\n",
      "tensor([0.1000, 0.1000, 0.3000])\n",
      "tensor([0.1000, 0.2000, 0.2000])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n",
      "tensor([0.1000, 0.3000, 0.2000])\n",
      "tensor([0.1000, 0.3000, 0.3000])\n",
      "tensor([0.1000, 0.4000, 0.2000])\n",
      "tensor([0.1000, 0.4000, 0.3000])\n",
      "tensor([0.1000, 0.5000, 0.2000])\n",
      "tensor([0.1000, 0.5000, 0.3000])\n",
      "tensor([0.1000, 0.6000, 0.2000])\n",
      "tensor([0.1000, 0.6000, 0.3000])\n",
      "tensor([0.1000, 0.7000, 0.2000])\n",
      "tensor([0.1000, 0.7000, 0.3000])\n",
      "tensor([0.1000, 0.8000, 0.2000])\n",
      "tensor([0.1000, 0.8000, 0.3000])\n",
      "tensor([0.1000, 0.9000, 0.2000])\n",
      "tensor([0.1000, 0.9000, 0.3000])\n",
      "tensor([ 0.2000, -1.0000,  0.2000])\n",
      "tensor([ 0.2000, -1.0000,  0.3000])\n",
      "tensor([ 0.2000, -0.9000,  0.2000])\n",
      "tensor([ 0.2000, -0.9000,  0.3000])\n",
      "tensor([ 0.2000, -0.8000,  0.2000])\n",
      "tensor([ 0.2000, -0.8000,  0.3000])\n",
      "tensor([ 0.2000, -0.7000,  0.2000])\n",
      "tensor([ 0.2000, -0.7000,  0.3000])\n",
      "tensor([ 0.2000, -0.6000,  0.2000])\n",
      "tensor([ 0.2000, -0.6000,  0.3000])\n",
      "tensor([ 0.2000, -0.5000,  0.2000])\n",
      "tensor([ 0.2000, -0.5000,  0.3000])\n",
      "tensor([ 0.2000, -0.4000,  0.2000])\n",
      "tensor([ 0.2000, -0.4000,  0.3000])\n",
      "tensor([ 0.2000, -0.3000,  0.2000])\n",
      "tensor([ 0.2000, -0.3000,  0.3000])\n",
      "tensor([ 0.2000, -0.2000,  0.2000])\n",
      "tensor([ 0.2000, -0.2000,  0.3000])\n",
      "tensor([ 0.2000, -0.1000,  0.2000])\n",
      "tensor([ 0.2000, -0.1000,  0.3000])\n",
      "tensor([2.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([2.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.2000, 0.1000, 0.2000])\n",
      "tensor([0.2000, 0.1000, 0.3000])\n",
      "tensor([0.2000, 0.2000, 0.2000])\n",
      "tensor([0.2000, 0.2000, 0.3000])\n",
      "tensor([0.2000, 0.3000, 0.2000])\n",
      "tensor([0.2000, 0.3000, 0.3000])\n",
      "tensor([0.2000, 0.4000, 0.2000])\n",
      "tensor([0.2000, 0.4000, 0.3000])\n",
      "tensor([0.2000, 0.5000, 0.2000])\n",
      "tensor([0.2000, 0.5000, 0.3000])\n",
      "tensor([0.2000, 0.6000, 0.2000])\n",
      "tensor([0.2000, 0.6000, 0.3000])\n",
      "tensor([0.2000, 0.7000, 0.2000])\n",
      "tensor([0.2000, 0.7000, 0.3000])\n",
      "tensor([0.2000, 0.8000, 0.2000])\n",
      "tensor([0.2000, 0.8000, 0.3000])\n",
      "tensor([0.2000, 0.9000, 0.2000])\n",
      "tensor([0.2000, 0.9000, 0.3000])\n",
      "tensor([ 0.3000, -1.0000,  0.2000])\n",
      "tensor([ 0.3000, -1.0000,  0.3000])\n",
      "tensor([ 0.3000, -0.9000,  0.2000])\n",
      "tensor([ 0.3000, -0.9000,  0.3000])\n",
      "tensor([ 0.3000, -0.8000,  0.2000])\n",
      "tensor([ 0.3000, -0.8000,  0.3000])\n",
      "tensor([ 0.3000, -0.7000,  0.2000])\n",
      "tensor([ 0.3000, -0.7000,  0.3000])\n",
      "tensor([ 0.3000, -0.6000,  0.2000])\n",
      "tensor([ 0.3000, -0.6000,  0.3000])\n",
      "tensor([ 0.3000, -0.5000,  0.2000])\n",
      "tensor([ 0.3000, -0.5000,  0.3000])\n",
      "tensor([ 0.3000, -0.4000,  0.2000])\n",
      "tensor([ 0.3000, -0.4000,  0.3000])\n",
      "tensor([ 0.3000, -0.3000,  0.2000])\n",
      "tensor([ 0.3000, -0.3000,  0.3000])\n",
      "tensor([ 0.3000, -0.2000,  0.2000])\n",
      "tensor([ 0.3000, -0.2000,  0.3000])\n",
      "tensor([ 0.3000, -0.1000,  0.2000])\n",
      "tensor([ 0.3000, -0.1000,  0.3000])\n",
      "tensor([3.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([3.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.3000, 0.1000, 0.2000])\n",
      "tensor([0.3000, 0.1000, 0.3000])\n",
      "tensor([0.3000, 0.2000, 0.2000])\n",
      "tensor([0.3000, 0.2000, 0.3000])\n",
      "tensor([0.3000, 0.3000, 0.2000])\n",
      "tensor([0.3000, 0.3000, 0.3000])\n",
      "tensor([0.3000, 0.4000, 0.2000])\n",
      "tensor([0.3000, 0.4000, 0.3000])\n",
      "tensor([0.3000, 0.5000, 0.2000])\n",
      "tensor([0.3000, 0.5000, 0.3000])\n",
      "tensor([0.3000, 0.6000, 0.2000])\n",
      "tensor([0.3000, 0.6000, 0.3000])\n",
      "tensor([0.3000, 0.7000, 0.2000])\n",
      "tensor([0.3000, 0.7000, 0.3000])\n",
      "tensor([0.3000, 0.8000, 0.2000])\n",
      "tensor([0.3000, 0.8000, 0.3000])\n",
      "tensor([0.3000, 0.9000, 0.2000])\n",
      "tensor([0.3000, 0.9000, 0.3000])\n",
      "tensor([ 0.4000, -1.0000,  0.2000])\n",
      "tensor([ 0.4000, -1.0000,  0.3000])\n",
      "tensor([ 0.4000, -0.9000,  0.2000])\n",
      "tensor([ 0.4000, -0.9000,  0.3000])\n",
      "tensor([ 0.4000, -0.8000,  0.2000])\n",
      "tensor([ 0.4000, -0.8000,  0.3000])\n",
      "tensor([ 0.4000, -0.7000,  0.2000])\n",
      "tensor([ 0.4000, -0.7000,  0.3000])\n",
      "tensor([ 0.4000, -0.6000,  0.2000])\n",
      "tensor([ 0.4000, -0.6000,  0.3000])\n",
      "tensor([ 0.4000, -0.5000,  0.2000])\n",
      "tensor([ 0.4000, -0.5000,  0.3000])\n",
      "tensor([ 0.4000, -0.4000,  0.2000])\n",
      "tensor([ 0.4000, -0.4000,  0.3000])\n",
      "tensor([ 0.4000, -0.3000,  0.2000])\n",
      "tensor([ 0.4000, -0.3000,  0.3000])\n",
      "tensor([ 0.4000, -0.2000,  0.2000])\n",
      "tensor([ 0.4000, -0.2000,  0.3000])\n",
      "tensor([ 0.4000, -0.1000,  0.2000])\n",
      "tensor([ 0.4000, -0.1000,  0.3000])\n",
      "tensor([4.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([4.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.4000, 0.1000, 0.2000])\n",
      "tensor([0.4000, 0.1000, 0.3000])\n",
      "tensor([0.4000, 0.2000, 0.2000])\n",
      "tensor([0.4000, 0.2000, 0.3000])\n",
      "tensor([0.4000, 0.3000, 0.2000])\n",
      "tensor([0.4000, 0.3000, 0.3000])\n",
      "tensor([0.4000, 0.4000, 0.2000])\n",
      "tensor([0.4000, 0.4000, 0.3000])\n",
      "tensor([0.4000, 0.5000, 0.2000])\n",
      "tensor([0.4000, 0.5000, 0.3000])\n",
      "tensor([0.4000, 0.6000, 0.2000])\n",
      "tensor([0.4000, 0.6000, 0.3000])\n",
      "tensor([0.4000, 0.7000, 0.2000])\n",
      "tensor([0.4000, 0.7000, 0.3000])\n",
      "tensor([0.4000, 0.8000, 0.2000])\n",
      "tensor([0.4000, 0.8000, 0.3000])\n",
      "tensor([0.4000, 0.9000, 0.2000])\n",
      "tensor([0.4000, 0.9000, 0.3000])\n",
      "tensor([ 0.5000, -1.0000,  0.2000])\n",
      "tensor([ 0.5000, -1.0000,  0.3000])\n",
      "tensor([ 0.5000, -0.9000,  0.2000])\n",
      "tensor([ 0.5000, -0.9000,  0.3000])\n",
      "tensor([ 0.5000, -0.8000,  0.2000])\n",
      "tensor([ 0.5000, -0.8000,  0.3000])\n",
      "tensor([ 0.5000, -0.7000,  0.2000])\n",
      "tensor([ 0.5000, -0.7000,  0.3000])\n",
      "tensor([ 0.5000, -0.6000,  0.2000])\n",
      "tensor([ 0.5000, -0.6000,  0.3000])\n",
      "tensor([ 0.5000, -0.5000,  0.2000])\n",
      "tensor([ 0.5000, -0.5000,  0.3000])\n",
      "tensor([ 0.5000, -0.4000,  0.2000])\n",
      "tensor([ 0.5000, -0.4000,  0.3000])\n",
      "tensor([ 0.5000, -0.3000,  0.2000])\n",
      "tensor([ 0.5000, -0.3000,  0.3000])\n",
      "tensor([ 0.5000, -0.2000,  0.2000])\n",
      "tensor([ 0.5000, -0.2000,  0.3000])\n",
      "tensor([ 0.5000, -0.1000,  0.2000])\n",
      "tensor([ 0.5000, -0.1000,  0.3000])\n",
      "tensor([5.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([5.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.5000, 0.1000, 0.2000])\n",
      "tensor([0.5000, 0.1000, 0.3000])\n",
      "tensor([0.5000, 0.2000, 0.2000])\n",
      "tensor([0.5000, 0.2000, 0.3000])\n",
      "tensor([0.5000, 0.3000, 0.2000])\n",
      "tensor([0.5000, 0.3000, 0.3000])\n",
      "tensor([0.5000, 0.4000, 0.2000])\n",
      "tensor([0.5000, 0.4000, 0.3000])\n",
      "tensor([0.5000, 0.5000, 0.2000])\n",
      "tensor([0.5000, 0.5000, 0.3000])\n",
      "tensor([0.5000, 0.6000, 0.2000])\n",
      "tensor([0.5000, 0.6000, 0.3000])\n",
      "tensor([0.5000, 0.7000, 0.2000])\n",
      "tensor([0.5000, 0.7000, 0.3000])\n",
      "tensor([0.5000, 0.8000, 0.2000])\n",
      "tensor([0.5000, 0.8000, 0.3000])\n",
      "tensor([0.5000, 0.9000, 0.2000])\n",
      "tensor([0.5000, 0.9000, 0.3000])\n",
      "tensor([ 0.6000, -1.0000,  0.2000])\n",
      "tensor([ 0.6000, -1.0000,  0.3000])\n",
      "tensor([ 0.6000, -0.9000,  0.2000])\n",
      "tensor([ 0.6000, -0.9000,  0.3000])\n",
      "tensor([ 0.6000, -0.8000,  0.2000])\n",
      "tensor([ 0.6000, -0.8000,  0.3000])\n",
      "tensor([ 0.6000, -0.7000,  0.2000])\n",
      "tensor([ 0.6000, -0.7000,  0.3000])\n",
      "tensor([ 0.6000, -0.6000,  0.2000])\n",
      "tensor([ 0.6000, -0.6000,  0.3000])\n",
      "tensor([ 0.6000, -0.5000,  0.2000])\n",
      "tensor([ 0.6000, -0.5000,  0.3000])\n",
      "tensor([ 0.6000, -0.4000,  0.2000])\n",
      "tensor([ 0.6000, -0.4000,  0.3000])\n",
      "tensor([ 0.6000, -0.3000,  0.2000])\n",
      "tensor([ 0.6000, -0.3000,  0.3000])\n",
      "tensor([ 0.6000, -0.2000,  0.2000])\n",
      "tensor([ 0.6000, -0.2000,  0.3000])\n",
      "tensor([ 0.6000, -0.1000,  0.2000])\n",
      "tensor([ 0.6000, -0.1000,  0.3000])\n",
      "tensor([6.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([6.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.6000, 0.1000, 0.2000])\n",
      "tensor([0.6000, 0.1000, 0.3000])\n",
      "tensor([0.6000, 0.2000, 0.2000])\n",
      "tensor([0.6000, 0.2000, 0.3000])\n",
      "tensor([0.6000, 0.3000, 0.2000])\n",
      "tensor([0.6000, 0.3000, 0.3000])\n",
      "tensor([0.6000, 0.4000, 0.2000])\n",
      "tensor([0.6000, 0.4000, 0.3000])\n",
      "tensor([0.6000, 0.5000, 0.2000])\n",
      "tensor([0.6000, 0.5000, 0.3000])\n",
      "tensor([0.6000, 0.6000, 0.2000])\n",
      "tensor([0.6000, 0.6000, 0.3000])\n",
      "tensor([0.6000, 0.7000, 0.2000])\n",
      "tensor([0.6000, 0.7000, 0.3000])\n",
      "tensor([0.6000, 0.8000, 0.2000])\n",
      "tensor([0.6000, 0.8000, 0.3000])\n",
      "tensor([0.6000, 0.9000, 0.2000])\n",
      "tensor([0.6000, 0.9000, 0.3000])\n",
      "tensor([ 0.7000, -1.0000,  0.2000])\n",
      "tensor([ 0.7000, -1.0000,  0.3000])\n",
      "tensor([ 0.7000, -0.9000,  0.2000])\n",
      "tensor([ 0.7000, -0.9000,  0.3000])\n",
      "tensor([ 0.7000, -0.8000,  0.2000])\n",
      "tensor([ 0.7000, -0.8000,  0.3000])\n",
      "tensor([ 0.7000, -0.7000,  0.2000])\n",
      "tensor([ 0.7000, -0.7000,  0.3000])\n",
      "tensor([ 0.7000, -0.6000,  0.2000])\n",
      "tensor([ 0.7000, -0.6000,  0.3000])\n",
      "tensor([ 0.7000, -0.5000,  0.2000])\n",
      "tensor([ 0.7000, -0.5000,  0.3000])\n",
      "tensor([ 0.7000, -0.4000,  0.2000])\n",
      "tensor([ 0.7000, -0.4000,  0.3000])\n",
      "tensor([ 0.7000, -0.3000,  0.2000])\n",
      "tensor([ 0.7000, -0.3000,  0.3000])\n",
      "tensor([ 0.7000, -0.2000,  0.2000])\n",
      "tensor([ 0.7000, -0.2000,  0.3000])\n",
      "tensor([ 0.7000, -0.1000,  0.2000])\n",
      "tensor([ 0.7000, -0.1000,  0.3000])\n",
      "tensor([7.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([7.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.7000, 0.1000, 0.2000])\n",
      "tensor([0.7000, 0.1000, 0.3000])\n",
      "tensor([0.7000, 0.2000, 0.2000])\n",
      "tensor([0.7000, 0.2000, 0.3000])\n",
      "tensor([0.7000, 0.3000, 0.2000])\n",
      "tensor([0.7000, 0.3000, 0.3000])\n",
      "tensor([0.7000, 0.4000, 0.2000])\n",
      "tensor([0.7000, 0.4000, 0.3000])\n",
      "tensor([0.7000, 0.5000, 0.2000])\n",
      "tensor([0.7000, 0.5000, 0.3000])\n",
      "tensor([0.7000, 0.6000, 0.2000])\n",
      "tensor([0.7000, 0.6000, 0.3000])\n",
      "tensor([0.7000, 0.7000, 0.2000])\n",
      "tensor([0.7000, 0.7000, 0.3000])\n",
      "tensor([0.7000, 0.8000, 0.2000])\n",
      "tensor([0.7000, 0.8000, 0.3000])\n",
      "tensor([0.7000, 0.9000, 0.2000])\n",
      "tensor([0.7000, 0.9000, 0.3000])\n",
      "tensor([ 0.8000, -1.0000,  0.2000])\n",
      "tensor([ 0.8000, -1.0000,  0.3000])\n",
      "tensor([ 0.8000, -0.9000,  0.2000])\n",
      "tensor([ 0.8000, -0.9000,  0.3000])\n",
      "tensor([ 0.8000, -0.8000,  0.2000])\n",
      "tensor([ 0.8000, -0.8000,  0.3000])\n",
      "tensor([ 0.8000, -0.7000,  0.2000])\n",
      "tensor([ 0.8000, -0.7000,  0.3000])\n",
      "tensor([ 0.8000, -0.6000,  0.2000])\n",
      "tensor([ 0.8000, -0.6000,  0.3000])\n",
      "tensor([ 0.8000, -0.5000,  0.2000])\n",
      "tensor([ 0.8000, -0.5000,  0.3000])\n",
      "tensor([ 0.8000, -0.4000,  0.2000])\n",
      "tensor([ 0.8000, -0.4000,  0.3000])\n",
      "tensor([ 0.8000, -0.3000,  0.2000])\n",
      "tensor([ 0.8000, -0.3000,  0.3000])\n",
      "tensor([ 0.8000, -0.2000,  0.2000])\n",
      "tensor([ 0.8000, -0.2000,  0.3000])\n",
      "tensor([ 0.8000, -0.1000,  0.2000])\n",
      "tensor([ 0.8000, -0.1000,  0.3000])\n",
      "tensor([8.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([8.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.8000, 0.1000, 0.2000])\n",
      "tensor([0.8000, 0.1000, 0.3000])\n",
      "tensor([0.8000, 0.2000, 0.2000])\n",
      "tensor([0.8000, 0.2000, 0.3000])\n",
      "tensor([0.8000, 0.3000, 0.2000])\n",
      "tensor([0.8000, 0.3000, 0.3000])\n",
      "tensor([0.8000, 0.4000, 0.2000])\n",
      "tensor([0.8000, 0.4000, 0.3000])\n",
      "tensor([0.8000, 0.5000, 0.2000])\n",
      "tensor([0.8000, 0.5000, 0.3000])\n",
      "tensor([0.8000, 0.6000, 0.2000])\n",
      "tensor([0.8000, 0.6000, 0.3000])\n",
      "tensor([0.8000, 0.7000, 0.2000])\n",
      "tensor([0.8000, 0.7000, 0.3000])\n",
      "tensor([0.8000, 0.8000, 0.2000])\n",
      "tensor([0.8000, 0.8000, 0.3000])\n",
      "tensor([0.8000, 0.9000, 0.2000])\n",
      "tensor([0.8000, 0.9000, 0.3000])\n",
      "tensor([ 0.9000, -1.0000,  0.2000])\n",
      "tensor([ 0.9000, -1.0000,  0.3000])\n",
      "tensor([ 0.9000, -0.9000,  0.2000])\n",
      "tensor([ 0.9000, -0.9000,  0.3000])\n",
      "tensor([ 0.9000, -0.8000,  0.2000])\n",
      "tensor([ 0.9000, -0.8000,  0.3000])\n",
      "tensor([ 0.9000, -0.7000,  0.2000])\n",
      "tensor([ 0.9000, -0.7000,  0.3000])\n",
      "tensor([ 0.9000, -0.6000,  0.2000])\n",
      "tensor([ 0.9000, -0.6000,  0.3000])\n",
      "tensor([ 0.9000, -0.5000,  0.2000])\n",
      "tensor([ 0.9000, -0.5000,  0.3000])\n",
      "tensor([ 0.9000, -0.4000,  0.2000])\n",
      "tensor([ 0.9000, -0.4000,  0.3000])\n",
      "tensor([ 0.9000, -0.3000,  0.2000])\n",
      "tensor([ 0.9000, -0.3000,  0.3000])\n",
      "tensor([ 0.9000, -0.2000,  0.2000])\n",
      "tensor([ 0.9000, -0.2000,  0.3000])\n",
      "tensor([ 0.9000, -0.1000,  0.2000])\n",
      "tensor([ 0.9000, -0.1000,  0.3000])\n",
      "tensor([9.0000e-01, 1.4901e-08, 2.0000e-01])\n",
      "tensor([9.0000e-01, 1.4901e-08, 3.0000e-01])\n",
      "tensor([0.9000, 0.1000, 0.2000])\n",
      "tensor([0.9000, 0.1000, 0.3000])\n",
      "tensor([0.9000, 0.2000, 0.2000])\n",
      "tensor([0.9000, 0.2000, 0.3000])\n",
      "tensor([0.9000, 0.3000, 0.2000])\n",
      "tensor([0.9000, 0.3000, 0.3000])\n",
      "tensor([0.9000, 0.4000, 0.2000])\n",
      "tensor([0.9000, 0.4000, 0.3000])\n",
      "tensor([0.9000, 0.5000, 0.2000])\n",
      "tensor([0.9000, 0.5000, 0.3000])\n",
      "tensor([0.9000, 0.6000, 0.2000])\n",
      "tensor([0.9000, 0.6000, 0.3000])\n",
      "tensor([0.9000, 0.7000, 0.2000])\n",
      "tensor([0.9000, 0.7000, 0.3000])\n",
      "tensor([0.9000, 0.8000, 0.2000])\n",
      "tensor([0.9000, 0.8000, 0.3000])\n",
      "tensor([0.9000, 0.9000, 0.2000])\n",
      "tensor([0.9000, 0.9000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "for point in points_generator:\n",
    "    print(torch.tensor(point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_generator = generate_parameter_points(param_ranges, param_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.7620871035666354\n"
     ]
    }
   ],
   "source": [
    "print(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2634e-17-4.2907e-18j,  2.0638e-02-1.3801e-02j,\n",
      "        -1.4873e-02-1.4024e-02j, -1.0300e-17+1.0365e-16j,\n",
      "        -2.9830e-02+5.1339e-03j, -1.4745e-16-9.8012e-17j,\n",
      "         1.2490e-16+5.0307e-17j,  1.4131e-01+1.3325e-01j,\n",
      "        -3.5634e-03+1.7197e-02j,  2.1684e-16-9.3675e-17j,\n",
      "        -2.2204e-16+1.8908e-16j,  5.4781e-02-2.6438e-01j,\n",
      "         8.8471e-17-1.1449e-16j, -3.1728e-01+2.1217e-01j,\n",
      "         2.8342e-01-4.8779e-02j,  1.0408e-17+1.8735e-16j,\n",
      "         2.7628e-02+5.4945e-03j, -8.0448e-17+8.5869e-17j,\n",
      "         5.0524e-17-1.5005e-16j, -1.9609e-01+1.3113e-01j,\n",
      "         4.5970e-17+9.5193e-17j,  4.5859e-01-7.8925e-02j,\n",
      "        -4.2473e-01-8.4469e-02j, -1.1449e-16-7.2858e-17j,\n",
      "        -1.0582e-16+4.5103e-17j, -2.6250e-01-5.2205e-02j,\n",
      "         2.2864e-01+2.1560e-01j,  1.6653e-16-1.5266e-16j,\n",
      "         3.3856e-02-1.6339e-01j, -1.3184e-16+1.8041e-16j,\n",
      "         1.4658e-16-1.8041e-16j, -4.0742e-16-3.0910e-16j],\n",
      "       dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "print(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def memoize(ham, param_range, param_step, directory):\n",
    "# \n",
    "#     points_generator = generate_parameter_points(param_range, param_step)\n",
    "# \n",
    "#     with open(directory, \"a\") as f:\n",
    "#         for point in points_generator:\n",
    "#             point_tensor = torch.tensor(point)\n",
    "#             energy, psi = ham.calc_ground(param=point_tensor)\n",
    "#             writer = csv.writer(io.BufferedWriter(f))\n",
    "#             row = \n",
    "#             writer.writerow([energy] + psi.tolist())\n",
    "#         \n",
    "# memoize(iham, param_ranges, param_steps, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2153502547.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    for point in points_generator\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def memoize(ham, param_range, param_step, directory, chunk_size):\n",
    "    points_generator = generate_parameter_points(param_range, param_step)\n",
    "    N = ham.n # TODO Hamiltonians should specify this on construction\n",
    "    NUM_PARAMS, _ = len(param_range)\n",
    "    CSV_COLUMNS = [\"energy\"] + [f\"param_{i}\" for i in range(NUM_PARAMS)] + [f\"psi_{i}\" for i in range(N)]\n",
    "\n",
    "    # Initialize a Pandas DataFrame of chunk_size rows to store the ground state energy and wavefunction\n",
    "    ground_df = pd.DataFrame(columns=CSV_COLUMNS)\n",
    "    \n",
    "    with open(directory, \"a\") as d:\n",
    "\n",
    "        # Iterate over points in the parameter space slice, calculating the ground state \n",
    "        # energy via brute force eigendecomposition at each point\n",
    "        for point in points_generator:\n",
    "            point_tensor = torch.tensor(point)\n",
    "            energy, psi = ham.calc_ground(param=point_tensor)\n",
    "            row = [energy] + psi.tolist()\n",
    "            ground_df.loc[len(ground_df)] = row\n",
    "\n",
    "            if len(ground_df) >= chunk_size:\n",
    "                ground_df.to_csv(d, index=False, header=False)\n",
    "                ground_df = pd.DataFrame(columns=[\"energy\"] + [f\"psi_{i}\" for i in range(N)])\n",
    "     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6.535028594656378e-17-3.29326409892472e-17j),\n",
       " (-0.023017877723499742+0.002903771622841847j),\n",
       " (-0.022104404116881554+0.020715625230426277j),\n",
       " (4.85722573273506e-17+2.393918396847994e-16j),\n",
       " (0.009356604678203831+0.009899188867766423j),\n",
       " (-1.249000902703301e-16+3.191891195797325e-16j),\n",
       " (1.249000902703301e-16-6.323067069935462e-16j),\n",
       " (0.21001894089410159-0.19682383871775952j),\n",
       " (0.027887103827307913-0.014597590049091922j),\n",
       " (2.7755575615628914e-17-1.0269562977782698e-15j),\n",
       " (3.608224830031759e-16+1.0547118733938987e-15j),\n",
       " (-0.42871700104345467+0.22441322939316016j),\n",
       " (-4.0245584642661925e-16-5.828670879282072e-16j),\n",
       " (0.3538608945953221-0.04464057184169812j),\n",
       " (-0.08889921639554305-0.09405443144840209j),\n",
       " (1.1212818867845087e-15+1.3877787807814457e-16j),\n",
       " (0.007878573334869646-0.018920995671942623j),\n",
       " (4.163336342344337e-16+5.828670879282072e-16j),\n",
       " (-4.163336342344337e-16-9.159339953157541e-16j),\n",
       " (0.21869806014935217-0.027589390675401865j),\n",
       " (8.014422459012849e-16+1.1102230246251565e-16j),\n",
       " (-0.14384195370121927-0.15218326687606026j),\n",
       " (-0.12111972449855951+0.2908782701661606j),\n",
       " (-1.7208456881689926e-15+4.996003610813204e-16j),\n",
       " (-4.0245584642661925e-16+3.8163916471489756e-16j),\n",
       " (-0.07485610644813387+0.17977265755146096j),\n",
       " (0.3398177846479131-0.3184676608415612j),\n",
       " (1.6653345369377348e-15-9.159339953157541e-16j),\n",
       " (-0.2649616781997801+0.13869500329009896j),\n",
       " (-9.020562075079397e-16+8.049116928532385e-16j),\n",
       " (3.469446951953614e-17-4.597017211338539e-16j),\n",
       " (-1.734723475976807e-17+9.645062526431047e-16j)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-Accelerated Ground State Label Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CuPy provides a direct analogue to Scipy's sparse Hermitian eigensolver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "from cupyx.scipy.sparse.linalg import eigsh as cuda_eigsh\n",
    "from cupyx.scipy.sparse import csr_matrix as cuda_csr_matrix\n",
    "from scipy.sparse.linalg import eigsh as eigsh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csmuser\\Desktop\\Spandan_Suthar_Research\\tqs\\Hamiltonian_utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  system_size = torch.tensor(system_size, dtype=torch.int64).reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "iham = Ising(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "full_ham = iham.full_H(param = 1)\n",
    "with open(\"full_ham.pkl\", \"wb\") as f:\n",
    "    pickle.dump(full_ham, f)\n",
    "print(type(full_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cupyx.scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "full_ham_cuda = cuda_csr_matrix(full_ham)\n",
    "with open(\"full_ham_cuda.pkl\", \"wb\") as f:\n",
    "    pickle.dump(full_ham_cuda, f)\n",
    "print(type(full_ham_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del full_ham\n",
    "del full_ham_cuda\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.490004777908325 s\n"
     ]
    }
   ],
   "source": [
    "full_ham_cuda = pickle.load(open(\"full_ham_cuda.pkl\", \"rb\"))\n",
    "start = time.time()\n",
    "eigenvalues, eigenvectors = cuda_eigsh(full_ham_cuda, k=1, which=\"SA\")\n",
    "end = time.time()\n",
    "del full_ham_cuda\n",
    "gc.collect()\n",
    "print(end - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ham = pickle.load(open(\"full_ham.pkl\", \"rb\"))\n",
    "start = time.time()\n",
    "eigenvalues, eigenvectors = eigsh(full_ham, k=1, which=\"SA\")\n",
    "end = time.time()\n",
    "del full_ham\n",
    "gc.collect()\n",
    "print(end - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: produced via Copilot:\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from cupyx.scipy.sparse.linalg import eigsh as cuda_eigsh\n",
    "\n",
    "def analyze_runtimes(chain_lengths, time_cutoff):\n",
    "    eigsh_runtimes = []\n",
    "    cuda_eigsh_runtimes = []\n",
    "\n",
    "    for length in chain_lengths:\n",
    "        # Create the Ising Hamiltonian\n",
    "        iham = Ising(length)\n",
    "        full_ham = iham.full_H(param=1)\n",
    "        full_ham_cuda = cuda_csr_matrix(full_ham)\n",
    "\n",
    "        # Run eigsh and measure the runtime\n",
    "        start_time = time.time()\n",
    "        eigsh(full_ham, k=1, which='SA')\n",
    "        end_time = time.time()\n",
    "        eigsh_runtime = end_time - start_time\n",
    "        eigsh_runtimes.append(eigsh_runtime)\n",
    "\n",
    "        # Run cuda_eigsh and measure the runtime\n",
    "        start_time = time.time()\n",
    "        cuda_eigsh(full_ham_cuda, k=1, which='SA')\n",
    "        end_time = time.time()\n",
    "        cuda_eigsh_runtime = end_time - start_time\n",
    "        cuda_eigsh_runtimes.append(cuda_eigsh_runtime)\n",
    "\n",
    "        # Check if the runtime exceeds the time cutoff\n",
    "        if eigsh_runtime > time_cutoff or cuda_eigsh_runtime > time_cutoff:\n",
    "            break\n",
    "\n",
    "    return eigsh_runtimes, cuda_eigsh_runtimes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
