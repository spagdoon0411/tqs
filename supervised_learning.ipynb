{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Supervised Optimizer\n",
    "\n",
    "From start to finish, on pretrained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from Hamiltonian import Ising\n",
    "from model import TransformerModel\n",
    "from optimizer_supervised import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/Projects/tqs/Hamiltonian_utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  system_size = torch.tensor(system_size, dtype=torch.int64).reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "system_sizes = np.arange(2, 20 + 1, 2)\n",
    "Hamiltonians = [Ising(L) for L in system_sizes]\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-07-24T19-26-39.836\")\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>h</th>\n",
       "      <th>energy</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-8.509082</td>\n",
       "      <td>[0.6605958050461614, 0.0840743972388362, 0.084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-8.530118</td>\n",
       "      <td>[0.6585782455420488, 0.085569590570777, 0.0855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-8.551616</td>\n",
       "      <td>[0.6565051975177678, 0.08705266382789387, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-8.573583</td>\n",
       "      <td>[0.6543751344281732, 0.08852320503071141, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-8.596021</td>\n",
       "      <td>[0.6521864366727165, 0.08998077886278089, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-13.107242</td>\n",
       "      <td>[0.25838376330919144, 0.11298188861835674, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-13.176419</td>\n",
       "      <td>[0.2558137133373303, 0.11260196191599145, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8</td>\n",
       "      <td>1.48</td>\n",
       "      <td>-13.245775</td>\n",
       "      <td>[0.2533008144129923, 0.11222628433594571, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8</td>\n",
       "      <td>1.49</td>\n",
       "      <td>-13.315306</td>\n",
       "      <td>[0.2508435516047006, 0.11185487885467213, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>8</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-13.385005</td>\n",
       "      <td>[0.24844043854066647, 0.11148775438956025, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     N     h     energy                                              state\n",
       "0    8  0.50  -8.509082  [0.6605958050461614, 0.0840743972388362, 0.084...\n",
       "1    8  0.51  -8.530118  [0.6585782455420488, 0.085569590570777, 0.0855...\n",
       "2    8  0.52  -8.551616  [0.6565051975177678, 0.08705266382789387, 0.08...\n",
       "3    8  0.53  -8.573583  [0.6543751344281732, 0.08852320503071141, 0.08...\n",
       "4    8  0.54  -8.596021  [0.6521864366727165, 0.08998077886278089, 0.08...\n",
       "..  ..   ...        ...                                                ...\n",
       "96   8  1.46 -13.107242  [0.25838376330919144, 0.11298188861835674, 0.1...\n",
       "97   8  1.47 -13.176419  [0.2558137133373303, 0.11260196191599145, 0.11...\n",
       "98   8  1.48 -13.245775  [0.2533008144129923, 0.11222628433594571, 0.11...\n",
       "99   8  1.49 -13.315306  [0.2508435516047006, 0.11185487885467213, 0.11...\n",
       "100  8  1.50 -13.385005  [0.24844043854066647, 0.11148775438956025, 0.1...\n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that data can be retrieved from Hamiltonians\n",
    "test_ham = Hamiltonians[3]  # Size 8\n",
    "test_ham.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.245775477442006\n",
      "tensor([0.2533, 0.1122, 0.1122, 0.0931, 0.1122, 0.0544, 0.0931, 0.0878, 0.1122,\n",
      "        0.0511, 0.0544, 0.0473, 0.0931, 0.0473, 0.0878, 0.0865, 0.1122, 0.0506,\n",
      "        0.0511, 0.0436, 0.0544, 0.0271, 0.0473, 0.0460, 0.0931, 0.0436, 0.0473,\n",
      "        0.0427, 0.0878, 0.0460, 0.0865, 0.0878, 0.1122, 0.0511, 0.0506, 0.0436,\n",
      "        0.0511, 0.0256, 0.0436, 0.0427, 0.0544, 0.0256, 0.0271, 0.0246, 0.0473,\n",
      "        0.0250, 0.0460, 0.0473, 0.0931, 0.0436, 0.0436, 0.0389, 0.0473, 0.0246,\n",
      "        0.0427, 0.0436, 0.0878, 0.0427, 0.0460, 0.0436, 0.0865, 0.0473, 0.0878,\n",
      "        0.0931, 0.1122, 0.0544, 0.0511, 0.0473, 0.0506, 0.0271, 0.0436, 0.0460,\n",
      "        0.0511, 0.0256, 0.0256, 0.0250, 0.0436, 0.0246, 0.0427, 0.0473, 0.0544,\n",
      "        0.0271, 0.0256, 0.0246, 0.0271, 0.0151, 0.0246, 0.0271, 0.0473, 0.0246,\n",
      "        0.0250, 0.0256, 0.0460, 0.0271, 0.0473, 0.0544, 0.0931, 0.0473, 0.0436,\n",
      "        0.0427, 0.0436, 0.0246, 0.0389, 0.0436, 0.0473, 0.0250, 0.0246, 0.0256,\n",
      "        0.0427, 0.0256, 0.0436, 0.0511, 0.0878, 0.0460, 0.0427, 0.0436, 0.0460,\n",
      "        0.0271, 0.0436, 0.0506, 0.0865, 0.0473, 0.0473, 0.0511, 0.0878, 0.0544,\n",
      "        0.0931, 0.1122, 0.1122, 0.0931, 0.0544, 0.0878, 0.0511, 0.0473, 0.0473,\n",
      "        0.0865, 0.0506, 0.0436, 0.0271, 0.0460, 0.0436, 0.0427, 0.0460, 0.0878,\n",
      "        0.0511, 0.0436, 0.0256, 0.0427, 0.0256, 0.0246, 0.0250, 0.0473, 0.0436,\n",
      "        0.0389, 0.0246, 0.0436, 0.0427, 0.0436, 0.0473, 0.0931, 0.0544, 0.0473,\n",
      "        0.0271, 0.0460, 0.0256, 0.0250, 0.0246, 0.0473, 0.0271, 0.0246, 0.0151,\n",
      "        0.0271, 0.0246, 0.0256, 0.0271, 0.0544, 0.0473, 0.0427, 0.0246, 0.0436,\n",
      "        0.0250, 0.0256, 0.0256, 0.0511, 0.0460, 0.0436, 0.0271, 0.0506, 0.0473,\n",
      "        0.0511, 0.0544, 0.1122, 0.0931, 0.0878, 0.0473, 0.0865, 0.0436, 0.0460,\n",
      "        0.0427, 0.0878, 0.0436, 0.0427, 0.0246, 0.0473, 0.0389, 0.0436, 0.0436,\n",
      "        0.0931, 0.0473, 0.0460, 0.0250, 0.0473, 0.0246, 0.0271, 0.0256, 0.0544,\n",
      "        0.0427, 0.0436, 0.0256, 0.0511, 0.0436, 0.0506, 0.0511, 0.1122, 0.0878,\n",
      "        0.0865, 0.0460, 0.0878, 0.0427, 0.0473, 0.0436, 0.0931, 0.0460, 0.0473,\n",
      "        0.0271, 0.0544, 0.0436, 0.0511, 0.0506, 0.1122, 0.0865, 0.0878, 0.0473,\n",
      "        0.0931, 0.0473, 0.0544, 0.0511, 0.1122, 0.0878, 0.0931, 0.0544, 0.1122,\n",
      "        0.0931, 0.1122, 0.1122, 0.2533], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "energy, state = test_ham.retrieve_ground(1.48)\n",
    "print(energy)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2533, 0.1122, 0.1122, 0.0931, 0.1122, 0.0544, 0.0931, 0.0878, 0.1122,\n",
       "         0.0511, 0.0544, 0.0473, 0.0931, 0.0473, 0.0878, 0.0865, 0.1122, 0.0506,\n",
       "         0.0511, 0.0436, 0.0544, 0.0271, 0.0473, 0.0460, 0.0931, 0.0436, 0.0473,\n",
       "         0.0427, 0.0878, 0.0460, 0.0865, 0.0878, 0.1122, 0.0511, 0.0506, 0.0436,\n",
       "         0.0511, 0.0256, 0.0436, 0.0427, 0.0544, 0.0256, 0.0271, 0.0246, 0.0473,\n",
       "         0.0250, 0.0460, 0.0473, 0.0931, 0.0436, 0.0436, 0.0389, 0.0473, 0.0246,\n",
       "         0.0427, 0.0436, 0.0878, 0.0427, 0.0460, 0.0436, 0.0865, 0.0473, 0.0878,\n",
       "         0.0931, 0.1122, 0.0544, 0.0511, 0.0473, 0.0506, 0.0271, 0.0436, 0.0460,\n",
       "         0.0511, 0.0256, 0.0256, 0.0250, 0.0436, 0.0246, 0.0427, 0.0473, 0.0544,\n",
       "         0.0271, 0.0256, 0.0246, 0.0271, 0.0151, 0.0246, 0.0271, 0.0473, 0.0246,\n",
       "         0.0250, 0.0256, 0.0460, 0.0271, 0.0473, 0.0544, 0.0931, 0.0473, 0.0436,\n",
       "         0.0427, 0.0436, 0.0246, 0.0389, 0.0436, 0.0473, 0.0250, 0.0246, 0.0256,\n",
       "         0.0427, 0.0256, 0.0436, 0.0511, 0.0878, 0.0460, 0.0427, 0.0436, 0.0460,\n",
       "         0.0271, 0.0436, 0.0506, 0.0865, 0.0473, 0.0473, 0.0511, 0.0878, 0.0544,\n",
       "         0.0931, 0.1122, 0.1122, 0.0931, 0.0544, 0.0878, 0.0511, 0.0473, 0.0473,\n",
       "         0.0865, 0.0506, 0.0436, 0.0271, 0.0460, 0.0436, 0.0427, 0.0460, 0.0878,\n",
       "         0.0511, 0.0436, 0.0256, 0.0427, 0.0256, 0.0246, 0.0250, 0.0473, 0.0436,\n",
       "         0.0389, 0.0246, 0.0436, 0.0427, 0.0436, 0.0473, 0.0931, 0.0544, 0.0473,\n",
       "         0.0271, 0.0460, 0.0256, 0.0250, 0.0246, 0.0473, 0.0271, 0.0246, 0.0151,\n",
       "         0.0271, 0.0246, 0.0256, 0.0271, 0.0544, 0.0473, 0.0427, 0.0246, 0.0436,\n",
       "         0.0250, 0.0256, 0.0256, 0.0511, 0.0460, 0.0436, 0.0271, 0.0506, 0.0473,\n",
       "         0.0511, 0.0544, 0.1122, 0.0931, 0.0878, 0.0473, 0.0865, 0.0436, 0.0460,\n",
       "         0.0427, 0.0878, 0.0436, 0.0427, 0.0246, 0.0473, 0.0389, 0.0436, 0.0436,\n",
       "         0.0931, 0.0473, 0.0460, 0.0250, 0.0473, 0.0246, 0.0271, 0.0256, 0.0544,\n",
       "         0.0427, 0.0436, 0.0256, 0.0511, 0.0436, 0.0506, 0.0511, 0.1122, 0.0878,\n",
       "         0.0865, 0.0460, 0.0878, 0.0427, 0.0473, 0.0436, 0.0931, 0.0460, 0.0473,\n",
       "         0.0271, 0.0544, 0.0436, 0.0511, 0.0506, 0.1122, 0.0865, 0.0878, 0.0473,\n",
       "         0.0931, 0.0473, 0.0544, 0.0511, 0.1122, 0.0878, 0.0931, 0.0544, 0.1122,\n",
       "         0.0931, 0.1122, 0.1122, 0.2533]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes:\n",
      " [[4]\n",
      " [6]\n",
      " [8]]\n",
      "Hamiltonians: [<Hamiltonian.Ising object at 0x7dc89ffeb770>, <Hamiltonian.Ising object at 0x7dc8a0f3fd70>, <Hamiltonian.Ising object at 0x7dc8a0e85130>]\n",
      "Dimensions of parameter space: 1\n",
      "Number of units in a feedforward layer: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/Projects/tqs/Hamiltonian_utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  system_size = torch.tensor(system_size, dtype=torch.int64).reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "system_sizes = np.arange(2, 20 + 1, 2).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]\n",
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 10000\n",
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False\n",
    "\n",
    "Hamiltonians = [Ising(L) for L in system_sizes]\n",
    "data_dir_path = os.path.join(\"TFIM_ground_states\", \"2024-07-24T19-26-39.836\")\n",
    "for ham in Hamiltonians:\n",
    "    ham.load_dataset(data_dir_path)\n",
    "\n",
    "print(\"Sizes:\\n\", system_sizes)\n",
    "print(\"Hamiltonians:\", Hamiltonians)\n",
    "print(\"Dimensions of parameter space:\", param_dim)\n",
    "print(\"Number of units in a feedforward layer:\", n_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")\n",
    "\n",
    "results_dir = \"results\"\n",
    "paper_checkpoint_name = \"ckpt_100000_Ising_32_8_8_0.ckpt\"\n",
    "paper_checkpoint_path = os.path.join(results_dir, paper_checkpoint_name)\n",
    "checkpoint = torch.load(paper_checkpoint_path)\n",
    "testmodel.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(testmodel, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Ground states not loaded yet. See load_dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m param_range \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.5\u001b[39m]])\n\u001b[1;32m      3\u001b[0m param_step \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.05\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m opt\u001b[38;5;241m.\u001b[39mtrain(epochs\u001b[38;5;241m=\u001b[39mepochs, param_range\u001b[38;5;241m=\u001b[39mparam_range, param_step\u001b[38;5;241m=\u001b[39mparam_step, start_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/tqs/optimizer_supervised.py:315\u001b[0m, in \u001b[0;36mOptimizer.train\u001b[0;34m(self, epochs, param_range, param_step, ensemble_id, start_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mset_param(system_size\u001b[38;5;241m=\u001b[39msystem_size, param\u001b[38;5;241m=\u001b[39mparam)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# NOTE: the system size is constant for this inner loop but must be reset\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# here because leaving it out (or, equivalently, setting it to None) would\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# cause the model to sample a random system size. See set_param in model.py.\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_mse_step(\n\u001b[1;32m    316\u001b[0m     H, param, basis_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_symmetry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    320\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Projects/tqs/optimizer_supervised.py:180\u001b[0m, in \u001b[0;36mOptimizer.calculate_mse_step\u001b[0;34m(self, H, params, basis_batch, use_symmetry)\u001b[0m\n\u001b[1;32m    175\u001b[0m psi_predicted \u001b[38;5;241m=\u001b[39m amp\u001b[38;5;241m.\u001b[39mmul(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m phase))\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Obtain the ground state wave function for the Hamiltonian H, possibly memoized internally\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# in the Hamiltonian object. This is the true wave function that the model's predictions\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# are compared against. TODO: implement memoization in Hamiltonian objects.\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m energy, psi_true \u001b[38;5;241m=\u001b[39m H\u001b[38;5;241m.\u001b[39mretrieve_ground(param\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# TODO: reshaping of psi_true necessary?\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Compute the mean squared error between the model's predictions and the true\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ground state wave function.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m psi_predicted_real_imag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(psi_predicted)\n",
      "File \u001b[0;32m~/Projects/tqs/Hamiltonian.py:479\u001b[0m, in \u001b[0;36mIsing.retrieve_ground\u001b[0;34m(self, param, abs_tol)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mGiven a parameter value and system size, retrieves the ground state as a PyTorch tensor--\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03mpossibly for use in supervised training.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m    The ground state wavefunction as a PyTorch tensor of shape (2**n, )\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround states not loaded yet. See load_dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Find the rows close to the parameter value (within abs_tol)\u001b[39;00m\n\u001b[1;32m    482\u001b[0m h_matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[np\u001b[38;5;241m.\u001b[39misclose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m], param, atol\u001b[38;5;241m=\u001b[39mabs_tol)]\n",
      "\u001b[0;31mValueError\u001b[0m: Ground states not loaded yet. See load_dataset."
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "param_range = torch.tensor([[0.5, 1.5]])\n",
    "param_step = torch.tensor([0.05])\n",
    "\n",
    "opt.train(epochs=epochs, param_range=param_range, param_step=param_step, start_iter=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4928,  0.1036,  0.1036,  ...,  0.1036,  0.1036, -0.4928],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = Hamiltonians[2]\n",
    "param = torch.tensor([0.8000])\n",
    "ground_energy, psi_true = H.calc_ground(param)\n",
    "psi_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 16384])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis = H.generate_basis()\n",
    "basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0506, -3.7310, -4.7868,  ..., -4.7868, -3.7310, -2.0506],\n",
      "       grad_fn=<LogBackward0>)\n",
      "tensor([-6.0865,  0.1709,  0.1618,  ...,  0.1618,  0.1709, -6.0865],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model_utils import compute_psi\n",
    "\n",
    "testmodel.set_param(system_size=H.system_size, param=param)\n",
    "log_amp, log_phase = compute_psi(testmodel, basis, H.symmetry, check_duplicate=True)\n",
    "print(log_amp)\n",
    "print(log_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
