{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_supervised import Optimizer\n",
    "from model import TransformerModel\n",
    "from Hamiltonian import Ising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    # Set the device to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU\")\n",
    "\n",
    "# Example usage: Move a tensor to the selected device\n",
    "x = torch.tensor([1, 2, 3])\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(\n",
    "    torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: [[ 8]\n",
      " [10]\n",
      " [12]\n",
      " [14]\n",
      " [16]\n",
      " [18]\n",
      " [20]]\n",
      "Hamiltonians: [<Hamiltonian.Ising object at 0x7cf4c14c1610>, <Hamiltonian.Ising object at 0x7cf4c14c1ac0>, <Hamiltonian.Ising object at 0x7cf4c14c2d50>, <Hamiltonian.Ising object at 0x7cf4c14c0dd0>, <Hamiltonian.Ising object at 0x7cf4c14c0f80>, <Hamiltonian.Ising object at 0x7cf4c1531400>, <Hamiltonian.Ising object at 0x7cf4c1530620>]\n",
      "Param dim: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/Projects/tqs/Hamiltonian_utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  system_size = torch.tensor(system_size, dtype=torch.int64).reshape(-1)\n"
     ]
    }
   ],
   "source": [
    "system_sizes = np.arange(8, 21, 2).reshape(-1, 1)\n",
    "Hamiltonians = [Ising(size, periodic=True) for size in system_sizes]\n",
    "param_dim = Hamiltonians[0].param_dim\n",
    "embedding_size = 32\n",
    "n_head = 8\n",
    "n_hid = embedding_size\n",
    "n_layers = 8\n",
    "dropout = 0\n",
    "minibatch = 10000\n",
    "\n",
    "print(\"Sizes:\", system_sizes)\n",
    "print(\"Hamiltonians:\", Hamiltonians)\n",
    "print(\"Param dim:\", param_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/anaconda3/envs/tqs2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    system_sizes,\n",
    "    param_dim,\n",
    "    embedding_size,\n",
    "    n_head,\n",
    "    n_hid,\n",
    "    n_layers,\n",
    "    dropout=dropout,\n",
    "    minibatch=minibatch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = None\n",
    "point_of_interest = None\n",
    "use_SR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Optimizer(model, Hamiltonians, point_of_interest=point_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "results_dir = \"results\"\n",
    "paper_checkpoint_name = \"ckpt_100000_Ising_32_8_8_0.ckpt\"\n",
    "paper_checkpoint_path = os.path.join(results_dir, paper_checkpoint_name)\n",
    "checkpoint = torch.load(paper_checkpoint_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.train(\n",
    "#     100,\n",
    "#     batch=1000000,\n",
    "#     max_unique=100,\n",
    "#     param_range=param_range,\n",
    "#     fine_tuning=False,\n",
    "#     use_SR=use_SR,\n",
    "#     ensemble_id=int(use_SR),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "tensor([8])\n"
     ]
    }
   ],
   "source": [
    "system_size = torch.tensor([8])\n",
    "param = torch.tensor([1])\n",
    "model.set_param(system_size=system_size, param=param)\n",
    "\n",
    "print(model.param)\n",
    "print(model.system_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = Hamiltonians[0]\n",
    "# batch = 100\n",
    "# max_unique = 10\n",
    "#\n",
    "# loss, log_amp, log_phase, sample_weight, Er, Ei, E_var = optim.minimize_energy_step(\n",
    "#     H, batch, max_unique, use_symmetry=True\n",
    "# )\n",
    "#\n",
    "# print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import compute_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_amp: tensor([-2.1063, -3.5020, -4.4347, -3.9910, -4.5754, -5.6357, -5.1850, -4.2139,\n",
      "        -4.6122, -5.8986, -6.6387, -5.9711, -5.4433, -6.2287, -5.4720, -4.2822,\n",
      "        -4.6122, -5.9522, -6.8316, -6.2947, -6.8066, -7.7291, -7.1625, -6.0609,\n",
      "        -5.5012, -6.6598, -7.2527, -6.3932, -5.7572, -6.3724, -5.5133, -4.2139,\n",
      "        -4.5754, -5.9320, -6.8459, -6.3498, -6.9398, -7.9307, -7.4386, -6.3932,\n",
      "        -6.8066, -8.0138, -8.6871, -7.9116, -7.3801, -8.0499, -7.2395, -5.9711,\n",
      "        -5.4433, -6.7123, -7.5403, -6.8796, -7.3801, -8.1650, -7.5054, -6.2947,\n",
      "        -5.7572, -6.8140, -7.3315, -6.3498, -5.7366, -6.2483, -5.3487, -3.9910,\n",
      "        -4.4347, -5.8027, -6.7256, -6.2483, -6.8459, -7.8620, -7.3858, -6.3724,\n",
      "        -6.8316, -8.0735, -8.7807, -8.0499, -7.5403, -8.2569, -7.4702, -6.2287,\n",
      "        -6.6387, -7.9333, -8.7807, -8.1650, -8.6871, -9.5224, -8.9023, -7.7291,\n",
      "        -7.2527, -8.3405, -8.8809, -7.9307, -7.3315, -7.8620, -6.9826, -5.6357,\n",
      "        -5.1850, -6.5075, -7.3858, -6.8140, -7.4386, -8.3405, -7.7942, -6.6598,\n",
      "        -7.1625, -8.2991, -8.9023, -8.0138, -7.5054, -8.0735, -7.2277, -5.8986,\n",
      "        -5.4720, -6.6915, -7.4702, -6.7123, -7.2395, -7.9333, -7.2277, -5.9522,\n",
      "        -5.5133, -6.5075, -6.9826, -5.9320, -5.3487, -5.8027, -4.8933, -3.5020,\n",
      "        -3.5020, -4.8933, -5.8027, -5.3487, -5.9320, -6.9826, -6.5075, -5.5133,\n",
      "        -5.9522, -7.2277, -7.9333, -7.2395, -6.7123, -7.4702, -6.6915, -5.4720,\n",
      "        -5.8986, -7.2277, -8.0735, -7.5054, -8.0138, -8.9023, -8.2991, -7.1625,\n",
      "        -6.6598, -7.7942, -8.3405, -7.4386, -6.8140, -7.3858, -6.5075, -5.1850,\n",
      "        -5.6357, -6.9826, -7.8620, -7.3315, -7.9307, -8.8809, -8.3405, -7.2527,\n",
      "        -7.7291, -8.9023, -9.5224, -8.6871, -8.1650, -8.7807, -7.9333, -6.6387,\n",
      "        -6.2287, -7.4702, -8.2569, -7.5403, -8.0499, -8.7807, -8.0735, -6.8316,\n",
      "        -6.3724, -7.3858, -7.8620, -6.8459, -6.2483, -6.7256, -5.8027, -4.4347,\n",
      "        -3.9910, -5.3487, -6.2483, -5.7366, -6.3498, -7.3315, -6.8140, -5.7572,\n",
      "        -6.2947, -7.5054, -8.1650, -7.3801, -6.8796, -7.5403, -6.7123, -5.4433,\n",
      "        -5.9711, -7.2395, -8.0499, -7.3801, -7.9116, -8.6871, -8.0138, -6.8066,\n",
      "        -6.3932, -7.4386, -7.9307, -6.9398, -6.3498, -6.8459, -5.9320, -4.5754,\n",
      "        -4.2139, -5.5133, -6.3724, -5.7572, -6.3932, -7.2527, -6.6598, -5.5012,\n",
      "        -6.0609, -7.1625, -7.7291, -6.8066, -6.2947, -6.8316, -5.9522, -4.6122,\n",
      "        -4.2822, -5.4720, -6.2287, -5.4433, -5.9711, -6.6387, -5.8986, -4.6122,\n",
      "        -4.2139, -5.1850, -5.6357, -4.5754, -3.9910, -4.4347, -3.5020, -2.1063],\n",
      "       grad_fn=<LogBackward0>)\n",
      "Log_phase: tensor([-0.1762,  6.1093,  6.1103, -0.1735,  6.1101, -0.1700, -0.1720,  6.1107,\n",
      "         6.1102, -0.1712, -0.1707,  6.1117, -0.1720,  6.1135,  6.1124, -0.1718,\n",
      "         6.1102, -0.1700, -0.1713,  6.1105, -0.1723,  6.1142,  6.1112, -0.1723,\n",
      "        -0.1724,  6.1110,  6.1125, -0.1721,  6.1095, -0.1700, -0.1709,  6.1107,\n",
      "         6.1101, -0.1695, -0.1703,  6.1115, -0.1728,  6.1146,  6.1101, -0.1721,\n",
      "        -0.1723,  6.1133,  6.1126, -0.1698,  6.1107, -0.1691, -0.1702,  6.1117,\n",
      "        -0.1720,  6.1128,  6.1108, -0.1740,  6.1107, -0.1698, -0.1715,  6.1105,\n",
      "         6.1095, -0.1726, -0.1696,  6.1115, -0.1736,  6.1133,  6.1126, -0.1735,\n",
      "         6.1103, -0.1685, -0.1692,  6.1133, -0.1703,  6.1168,  6.1126, -0.1700,\n",
      "        -0.1713,  6.1142,  6.1144, -0.1691,  6.1108, -0.1699, -0.1693,  6.1135,\n",
      "        -0.1707,  6.1155,  6.1144, -0.1698,  6.1126, -0.1681, -0.1691,  6.1142,\n",
      "         6.1125, -0.1694, -0.1673,  6.1146, -0.1696,  6.1168,  6.1162, -0.1700,\n",
      "        -0.1720,  6.1145,  6.1126, -0.1726,  6.1101, -0.1694, -0.1732,  6.1110,\n",
      "         6.1112, -0.1694, -0.1691,  6.1133, -0.1715,  6.1142,  6.1154, -0.1712,\n",
      "         6.1124, -0.1686, -0.1693,  6.1128, -0.1702,  6.1155,  6.1154, -0.1700,\n",
      "        -0.1709,  6.1145,  6.1162, -0.1695,  6.1126, -0.1685, -0.1689,  6.1093,\n",
      "         6.1093, -0.1689, -0.1685,  6.1126, -0.1695,  6.1162,  6.1145, -0.1709,\n",
      "        -0.1700,  6.1154,  6.1155, -0.1702,  6.1128, -0.1693, -0.1686,  6.1124,\n",
      "        -0.1712,  6.1154,  6.1142, -0.1715,  6.1133, -0.1691, -0.1694,  6.1112,\n",
      "         6.1110, -0.1732, -0.1694,  6.1101, -0.1726,  6.1126,  6.1145, -0.1720,\n",
      "        -0.1700,  6.1162,  6.1168, -0.1696,  6.1146, -0.1673, -0.1694,  6.1125,\n",
      "         6.1142, -0.1691, -0.1681,  6.1126, -0.1698,  6.1144,  6.1155, -0.1707,\n",
      "         6.1135, -0.1693, -0.1699,  6.1108, -0.1691,  6.1144,  6.1142, -0.1713,\n",
      "        -0.1700,  6.1126,  6.1168, -0.1703,  6.1133, -0.1692, -0.1685,  6.1103,\n",
      "        -0.1735,  6.1126,  6.1133, -0.1736,  6.1115, -0.1696, -0.1726,  6.1095,\n",
      "         6.1105, -0.1715, -0.1698,  6.1107, -0.1740,  6.1108,  6.1128, -0.1720,\n",
      "         6.1117, -0.1702, -0.1691,  6.1107, -0.1698,  6.1126,  6.1133, -0.1723,\n",
      "        -0.1721,  6.1101,  6.1146, -0.1728,  6.1115, -0.1703, -0.1695,  6.1101,\n",
      "         6.1107, -0.1709, -0.1700,  6.1095, -0.1721,  6.1125,  6.1110, -0.1724,\n",
      "        -0.1723,  6.1112,  6.1142, -0.1723,  6.1105, -0.1713, -0.1700,  6.1102,\n",
      "        -0.1718,  6.1124,  6.1135, -0.1720,  6.1117, -0.1707, -0.1712,  6.1102,\n",
      "         6.1107, -0.1720, -0.1700,  6.1101, -0.1735,  6.1103,  6.1093, -0.1762],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "H = Hamiltonians[0]\n",
    "basis = torch.tensor(H.generate_basis())\n",
    "symmetry = H.symmetry\n",
    "log_amp, log_phase = compute_psi(model, basis, symmetry, check_duplicate=True)\n",
    "print(\"Log_amp:\", log_amp)\n",
    "print(\"Log_phase:\", log_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(H.generate_basis())[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite nice that the phases are a periodic sequence:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amplitude: tensor([0.3488, 0.1736, 0.1089, 0.1359, 0.1015, 0.0597, 0.0748, 0.1216, 0.0996,\n",
      "        0.0524, 0.0362, 0.0505, 0.0658, 0.0444, 0.0648, 0.1175, 0.0996, 0.0510,\n",
      "        0.0328, 0.0430, 0.0333, 0.0210, 0.0278, 0.0483, 0.0639, 0.0358, 0.0266,\n",
      "        0.0409, 0.0562, 0.0413, 0.0635, 0.1216, 0.1015, 0.0515, 0.0326, 0.0418,\n",
      "        0.0311, 0.0190, 0.0243, 0.0409, 0.0333, 0.0182, 0.0130, 0.0191, 0.0250,\n",
      "        0.0179, 0.0268, 0.0505, 0.0658, 0.0349, 0.0230, 0.0321, 0.0250, 0.0169,\n",
      "        0.0235, 0.0430, 0.0562, 0.0331, 0.0256, 0.0418, 0.0568, 0.0440, 0.0690,\n",
      "        0.1359, 0.1089, 0.0549, 0.0346, 0.0440, 0.0326, 0.0196, 0.0249, 0.0413,\n",
      "        0.0328, 0.0177, 0.0124, 0.0179, 0.0230, 0.0161, 0.0239, 0.0444, 0.0362,\n",
      "        0.0189, 0.0124, 0.0169, 0.0130, 0.0086, 0.0117, 0.0210, 0.0266, 0.0154,\n",
      "        0.0118, 0.0190, 0.0256, 0.0196, 0.0305, 0.0597, 0.0748, 0.0386, 0.0249,\n",
      "        0.0331, 0.0243, 0.0154, 0.0203, 0.0358, 0.0278, 0.0158, 0.0117, 0.0182,\n",
      "        0.0235, 0.0177, 0.0269, 0.0524, 0.0648, 0.0352, 0.0239, 0.0349, 0.0268,\n",
      "        0.0189, 0.0269, 0.0510, 0.0635, 0.0386, 0.0305, 0.0515, 0.0690, 0.0549,\n",
      "        0.0866, 0.1736, 0.1736, 0.0866, 0.0549, 0.0690, 0.0515, 0.0305, 0.0386,\n",
      "        0.0635, 0.0510, 0.0269, 0.0189, 0.0268, 0.0349, 0.0239, 0.0352, 0.0648,\n",
      "        0.0524, 0.0269, 0.0177, 0.0235, 0.0182, 0.0117, 0.0158, 0.0278, 0.0358,\n",
      "        0.0203, 0.0154, 0.0243, 0.0331, 0.0249, 0.0386, 0.0748, 0.0597, 0.0305,\n",
      "        0.0196, 0.0256, 0.0190, 0.0118, 0.0154, 0.0266, 0.0210, 0.0117, 0.0086,\n",
      "        0.0130, 0.0169, 0.0124, 0.0189, 0.0362, 0.0444, 0.0239, 0.0161, 0.0230,\n",
      "        0.0179, 0.0124, 0.0177, 0.0328, 0.0413, 0.0249, 0.0196, 0.0326, 0.0440,\n",
      "        0.0346, 0.0549, 0.1089, 0.1359, 0.0690, 0.0440, 0.0568, 0.0418, 0.0256,\n",
      "        0.0331, 0.0562, 0.0430, 0.0235, 0.0169, 0.0250, 0.0321, 0.0230, 0.0349,\n",
      "        0.0658, 0.0505, 0.0268, 0.0179, 0.0250, 0.0191, 0.0130, 0.0182, 0.0333,\n",
      "        0.0409, 0.0243, 0.0190, 0.0311, 0.0418, 0.0326, 0.0515, 0.1015, 0.1216,\n",
      "        0.0635, 0.0413, 0.0562, 0.0409, 0.0266, 0.0358, 0.0639, 0.0483, 0.0278,\n",
      "        0.0210, 0.0333, 0.0430, 0.0328, 0.0510, 0.0996, 0.1175, 0.0648, 0.0444,\n",
      "        0.0658, 0.0505, 0.0362, 0.0524, 0.0996, 0.1216, 0.0748, 0.0597, 0.1015,\n",
      "        0.1359, 0.1089, 0.1736, 0.3488], grad_fn=<SqrtBackward0>)\n",
      "Phase: tensor([  0.4192, 225.0049, 225.2419,   0.4203, 225.1997,   0.4218,   0.4210,\n",
      "        225.3330, 225.2193,   0.4213,   0.4216, 225.5437,   0.4210, 225.9521,\n",
      "        225.7108,   0.4211, 225.2193,   0.4218,   0.4213, 225.2888,   0.4208,\n",
      "        226.1253, 225.4429,   0.4209,   0.4208, 225.4006, 225.7366,   0.4210,\n",
      "        225.0632,   0.4218,   0.4215, 225.3330, 225.1997,   0.4221,   0.4217,\n",
      "        225.5128,   0.4207, 226.2118, 225.1840,   0.4210,   0.4208, 225.9084,\n",
      "        225.7607,   0.4219, 225.3323,   0.4222,   0.4218, 225.5437,   0.4210,\n",
      "        225.8100, 225.3387,   0.4202, 225.3323,   0.4219,   0.4212, 225.2888,\n",
      "        225.0632,   0.4207,   0.4220, 225.5128,   0.4203, 225.9042, 225.7582,\n",
      "          0.4203, 225.2419,   0.4225,   0.4221, 225.9042,   0.4217, 226.7055,\n",
      "        225.7549,   0.4218,   0.4213, 226.1161, 226.1676,   0.4222, 225.3387,\n",
      "          0.4219,   0.4221, 225.9521,   0.4216, 226.4174, 226.1676,   0.4219,\n",
      "        225.7607,   0.4226,   0.4222, 226.1253, 225.7366,   0.4221,   0.4230,\n",
      "        226.2118,   0.4220, 226.7055, 226.5618,   0.4218,   0.4210, 226.1754,\n",
      "        225.7549,   0.4207, 225.1840,   0.4221,   0.4205, 225.4006, 225.4429,\n",
      "          0.4221,   0.4222, 225.9084,   0.4212, 226.1161, 226.3891,   0.4213,\n",
      "        225.7108,   0.4224,   0.4221, 225.8100,   0.4218, 226.4174, 226.3891,\n",
      "          0.4218,   0.4215, 226.1754, 226.5618,   0.4221, 225.7582,   0.4225,\n",
      "          0.4223, 225.0049, 225.0049,   0.4223,   0.4225, 225.7582,   0.4221,\n",
      "        226.5618, 226.1754,   0.4215,   0.4218, 226.3891, 226.4174,   0.4218,\n",
      "        225.8100,   0.4221,   0.4224, 225.7108,   0.4213, 226.3891, 226.1161,\n",
      "          0.4212, 225.9084,   0.4222,   0.4221, 225.4429, 225.4006,   0.4205,\n",
      "          0.4221, 225.1841,   0.4207, 225.7549, 226.1754,   0.4210,   0.4218,\n",
      "        226.5618, 226.7055,   0.4220, 226.2118,   0.4230,   0.4221, 225.7366,\n",
      "        226.1253,   0.4222,   0.4226, 225.7607,   0.4219, 226.1676, 226.4174,\n",
      "          0.4216, 225.9521,   0.4221,   0.4219, 225.3387,   0.4222, 226.1676,\n",
      "        226.1161,   0.4213,   0.4218, 225.7549, 226.7055,   0.4217, 225.9042,\n",
      "          0.4221,   0.4225, 225.2419,   0.4203, 225.7582, 225.9042,   0.4203,\n",
      "        225.5128,   0.4220,   0.4207, 225.0632, 225.2888,   0.4212,   0.4219,\n",
      "        225.3323,   0.4202, 225.3387, 225.8100,   0.4210, 225.5437,   0.4218,\n",
      "          0.4222, 225.3323,   0.4219, 225.7607, 225.9084,   0.4208,   0.4210,\n",
      "        225.1841, 226.2118,   0.4207, 225.5128,   0.4217,   0.4221, 225.1997,\n",
      "        225.3330,   0.4215,   0.4218, 225.0632,   0.4210, 225.7366, 225.4006,\n",
      "          0.4208,   0.4209, 225.4429, 226.1253,   0.4208, 225.2888,   0.4213,\n",
      "          0.4218, 225.2193,   0.4211, 225.7108, 225.9521,   0.4210, 225.5437,\n",
      "          0.4216,   0.4213, 225.2193, 225.3330,   0.4210,   0.4218, 225.1997,\n",
      "          0.4203, 225.2419, 225.0049,   0.4192], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "amp = torch.sqrt(torch.exp(log_amp))\n",
    "phase = torch.exp(log_phase)\n",
    "\n",
    "print(\"Amplitude:\", amp)\n",
    "print(\"Phase:\", phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3186+0.1420j, 0.0645-0.1612j, 0.0631-0.0888j, 0.1241+0.0555j,\n",
      "        0.0553-0.0851j, 0.0545+0.0245j, 0.0683+0.0306j, 0.0792-0.0923j,\n",
      "        0.0559-0.0825j, 0.0478+0.0214j, 0.0330+0.0148j, 0.0402-0.0306j,\n",
      "        0.0600+0.0269j, 0.0431-0.0107j, 0.0574-0.0302j, 0.1073+0.0480j,\n",
      "        0.0559-0.0825j, 0.0465+0.0209j, 0.0300+0.0134j, 0.0265-0.0338j,\n",
      "        0.0304+0.0136j, 0.0209-0.0015j, 0.0203-0.0190j, 0.0441+0.0197j,\n",
      "        0.0583+0.0261j, 0.0251-0.0255j, 0.0239-0.0118j, 0.0373+0.0167j,\n",
      "        0.0239-0.0509j, 0.0377+0.0169j, 0.0579+0.0260j, 0.0792-0.0923j,\n",
      "        0.0553-0.0851j, 0.0470+0.0211j, 0.0298+0.0134j, 0.0325-0.0263j,\n",
      "        0.0284+0.0127j, 0.0190+0.0003j, 0.0129-0.0205j, 0.0373+0.0167j,\n",
      "        0.0304+0.0136j, 0.0174-0.0051j, 0.0118-0.0055j, 0.0175+0.0078j,\n",
      "        0.0162-0.0190j, 0.0163+0.0073j, 0.0244+0.0110j, 0.0402-0.0306j,\n",
      "        0.0600+0.0269j, 0.0323-0.0131j, 0.0151-0.0174j, 0.0293+0.0131j,\n",
      "        0.0162-0.0190j, 0.0154+0.0069j, 0.0214+0.0096j, 0.0265-0.0338j,\n",
      "        0.0239-0.0509j, 0.0303+0.0135j, 0.0233+0.0105j, 0.0325-0.0263j,\n",
      "        0.0519+0.0232j, 0.0421-0.0126j, 0.0625-0.0291j, 0.1241+0.0555j,\n",
      "        0.0631-0.0888j, 0.0501+0.0225j, 0.0316+0.0142j, 0.0421-0.0126j,\n",
      "        0.0298+0.0134j, 0.0171+0.0096j, 0.0225-0.0106j, 0.0377+0.0169j,\n",
      "        0.0300+0.0134j, 0.0176-0.0014j, 0.0124-0.0003j, 0.0163+0.0073j,\n",
      "        0.0151-0.0174j, 0.0147+0.0066j, 0.0218+0.0098j, 0.0431-0.0107j,\n",
      "        0.0330+0.0148j, 0.0185+0.0042j, 0.0124-0.0003j, 0.0154+0.0069j,\n",
      "        0.0118-0.0055j, 0.0078+0.0035j, 0.0106+0.0048j, 0.0209-0.0015j,\n",
      "        0.0239-0.0118j, 0.0141+0.0063j, 0.0108+0.0048j, 0.0190+0.0003j,\n",
      "        0.0233+0.0105j, 0.0171+0.0096j, 0.0284+0.0109j, 0.0545+0.0245j,\n",
      "        0.0683+0.0306j, 0.0386-0.0007j, 0.0225-0.0106j, 0.0303+0.0135j,\n",
      "        0.0129-0.0205j, 0.0141+0.0063j, 0.0185+0.0083j, 0.0251-0.0255j,\n",
      "        0.0203-0.0190j, 0.0144+0.0065j, 0.0106+0.0048j, 0.0174-0.0051j,\n",
      "        0.0214+0.0096j, 0.0176-0.0014j, 0.0264+0.0052j, 0.0478+0.0214j,\n",
      "        0.0574-0.0302j, 0.0321+0.0144j, 0.0218+0.0098j, 0.0323-0.0131j,\n",
      "        0.0244+0.0110j, 0.0185+0.0042j, 0.0264+0.0052j, 0.0465+0.0209j,\n",
      "        0.0579+0.0260j, 0.0386-0.0007j, 0.0284+0.0109j, 0.0470+0.0211j,\n",
      "        0.0625-0.0291j, 0.0501+0.0225j, 0.0790+0.0355j, 0.0645-0.1612j,\n",
      "        0.0645-0.1612j, 0.0790+0.0355j, 0.0501+0.0225j, 0.0625-0.0291j,\n",
      "        0.0470+0.0211j, 0.0284+0.0109j, 0.0386-0.0007j, 0.0579+0.0260j,\n",
      "        0.0465+0.0209j, 0.0264+0.0052j, 0.0185+0.0042j, 0.0244+0.0110j,\n",
      "        0.0323-0.0131j, 0.0218+0.0098j, 0.0321+0.0144j, 0.0574-0.0302j,\n",
      "        0.0478+0.0214j, 0.0264+0.0052j, 0.0176-0.0014j, 0.0214+0.0096j,\n",
      "        0.0174-0.0051j, 0.0106+0.0048j, 0.0144+0.0065j, 0.0203-0.0190j,\n",
      "        0.0251-0.0255j, 0.0185+0.0083j, 0.0141+0.0063j, 0.0129-0.0205j,\n",
      "        0.0303+0.0135j, 0.0225-0.0106j, 0.0386-0.0007j, 0.0683+0.0306j,\n",
      "        0.0545+0.0245j, 0.0284+0.0109j, 0.0171+0.0096j, 0.0233+0.0105j,\n",
      "        0.0190+0.0003j, 0.0108+0.0048j, 0.0141+0.0063j, 0.0239-0.0118j,\n",
      "        0.0209-0.0015j, 0.0106+0.0048j, 0.0078+0.0035j, 0.0118-0.0055j,\n",
      "        0.0154+0.0069j, 0.0124-0.0003j, 0.0185+0.0042j, 0.0330+0.0148j,\n",
      "        0.0431-0.0107j, 0.0218+0.0098j, 0.0147+0.0066j, 0.0151-0.0174j,\n",
      "        0.0163+0.0073j, 0.0124-0.0003j, 0.0176-0.0014j, 0.0300+0.0134j,\n",
      "        0.0377+0.0169j, 0.0225-0.0106j, 0.0171+0.0096j, 0.0298+0.0134j,\n",
      "        0.0421-0.0126j, 0.0316+0.0142j, 0.0501+0.0225j, 0.0631-0.0888j,\n",
      "        0.1241+0.0555j, 0.0625-0.0291j, 0.0421-0.0126j, 0.0519+0.0232j,\n",
      "        0.0325-0.0263j, 0.0233+0.0105j, 0.0303+0.0135j, 0.0239-0.0509j,\n",
      "        0.0265-0.0338j, 0.0214+0.0096j, 0.0154+0.0069j, 0.0162-0.0190j,\n",
      "        0.0293+0.0131j, 0.0151-0.0174j, 0.0323-0.0131j, 0.0600+0.0269j,\n",
      "        0.0402-0.0306j, 0.0244+0.0110j, 0.0163+0.0073j, 0.0162-0.0190j,\n",
      "        0.0175+0.0078j, 0.0118-0.0055j, 0.0174-0.0051j, 0.0304+0.0136j,\n",
      "        0.0373+0.0167j, 0.0129-0.0205j, 0.0190+0.0003j, 0.0284+0.0127j,\n",
      "        0.0325-0.0263j, 0.0298+0.0134j, 0.0470+0.0211j, 0.0553-0.0851j,\n",
      "        0.0792-0.0923j, 0.0579+0.0260j, 0.0377+0.0169j, 0.0239-0.0509j,\n",
      "        0.0373+0.0167j, 0.0239-0.0118j, 0.0251-0.0255j, 0.0583+0.0261j,\n",
      "        0.0441+0.0197j, 0.0203-0.0190j, 0.0209-0.0015j, 0.0304+0.0136j,\n",
      "        0.0265-0.0338j, 0.0300+0.0134j, 0.0465+0.0209j, 0.0559-0.0825j,\n",
      "        0.1073+0.0480j, 0.0574-0.0302j, 0.0431-0.0107j, 0.0600+0.0269j,\n",
      "        0.0402-0.0306j, 0.0330+0.0148j, 0.0478+0.0214j, 0.0559-0.0825j,\n",
      "        0.0792-0.0923j, 0.0683+0.0306j, 0.0545+0.0245j, 0.0553-0.0851j,\n",
      "        0.1241+0.0555j, 0.0631-0.0888j, 0.0645-0.1612j, 0.3186+0.1420j],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "psi_predicted = amp * torch.exp(1j * phase)\n",
    "print(psi_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4591, -0.1292, -0.1292,  0.0774, -0.1292,  0.0404,  0.0774, -0.0607,\n",
      "        -0.1292,  0.0378,  0.0404, -0.0274,  0.0774, -0.0274, -0.0607,  0.0564,\n",
      "        -0.1292,  0.0375,  0.0378, -0.0246,  0.0404, -0.0137, -0.0274,  0.0247,\n",
      "         0.0774, -0.0246, -0.0274,  0.0221, -0.0607,  0.0247,  0.0564, -0.0607,\n",
      "        -0.1292,  0.0378,  0.0375, -0.0246,  0.0378, -0.0128, -0.0246,  0.0221,\n",
      "         0.0404, -0.0128, -0.0137,  0.0110, -0.0274,  0.0113,  0.0247, -0.0274,\n",
      "         0.0774, -0.0246, -0.0246,  0.0192, -0.0274,  0.0110,  0.0221, -0.0246,\n",
      "        -0.0607,  0.0221,  0.0247, -0.0246,  0.0564, -0.0274, -0.0607,  0.0774,\n",
      "        -0.1292,  0.0404,  0.0378, -0.0274,  0.0375, -0.0137, -0.0246,  0.0247,\n",
      "         0.0378, -0.0128, -0.0128,  0.0113, -0.0246,  0.0110,  0.0221, -0.0274,\n",
      "         0.0404, -0.0137, -0.0128,  0.0110, -0.0137,  0.0060,  0.0110, -0.0137,\n",
      "        -0.0274,  0.0110,  0.0113, -0.0128,  0.0247, -0.0137, -0.0274,  0.0404,\n",
      "         0.0774, -0.0274, -0.0246,  0.0221, -0.0246,  0.0110,  0.0192, -0.0246,\n",
      "        -0.0274,  0.0113,  0.0110, -0.0128,  0.0221, -0.0128, -0.0246,  0.0378,\n",
      "        -0.0607,  0.0247,  0.0221, -0.0246,  0.0247, -0.0137, -0.0246,  0.0375,\n",
      "         0.0564, -0.0274, -0.0274,  0.0378, -0.0607,  0.0404,  0.0774, -0.1292,\n",
      "        -0.1292,  0.0774,  0.0404, -0.0607,  0.0378, -0.0274, -0.0274,  0.0564,\n",
      "         0.0375, -0.0246, -0.0137,  0.0247, -0.0246,  0.0221,  0.0247, -0.0607,\n",
      "         0.0378, -0.0246, -0.0128,  0.0221, -0.0128,  0.0110,  0.0113, -0.0274,\n",
      "        -0.0246,  0.0192,  0.0110, -0.0246,  0.0221, -0.0246, -0.0274,  0.0774,\n",
      "         0.0404, -0.0274, -0.0137,  0.0247, -0.0128,  0.0113,  0.0110, -0.0274,\n",
      "        -0.0137,  0.0110,  0.0060, -0.0137,  0.0110, -0.0128, -0.0137,  0.0404,\n",
      "        -0.0274,  0.0221,  0.0110, -0.0246,  0.0113, -0.0128, -0.0128,  0.0378,\n",
      "         0.0247, -0.0246, -0.0137,  0.0375, -0.0274,  0.0378,  0.0404, -0.1292,\n",
      "         0.0774, -0.0607, -0.0274,  0.0564, -0.0246,  0.0247,  0.0221, -0.0607,\n",
      "        -0.0246,  0.0221,  0.0110, -0.0274,  0.0192, -0.0246, -0.0246,  0.0774,\n",
      "        -0.0274,  0.0247,  0.0113, -0.0274,  0.0110, -0.0137, -0.0128,  0.0404,\n",
      "         0.0221, -0.0246, -0.0128,  0.0378, -0.0246,  0.0375,  0.0378, -0.1292,\n",
      "        -0.0607,  0.0564,  0.0247, -0.0607,  0.0221, -0.0274, -0.0246,  0.0774,\n",
      "         0.0247, -0.0274, -0.0137,  0.0404, -0.0246,  0.0378,  0.0375, -0.1292,\n",
      "         0.0564, -0.0607, -0.0274,  0.0774, -0.0274,  0.0404,  0.0378, -0.1292,\n",
      "        -0.0607,  0.0774,  0.0404, -0.1292,  0.0774, -0.1292, -0.1292,  0.4591],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "energy, psi_true = H.calc_ground(param=1)\n",
    "psi_true = torch.tensor(psi_true)\n",
    "print(psi_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it just a phase difference?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3488, 0.1736, 0.1089, 0.1359, 0.1015, 0.0597, 0.0748, 0.1216, 0.0996,\n",
      "        0.0524, 0.0362, 0.0505, 0.0658, 0.0444, 0.0648, 0.1175, 0.0996, 0.0510,\n",
      "        0.0328, 0.0430, 0.0333, 0.0210, 0.0278, 0.0483, 0.0639, 0.0358, 0.0266,\n",
      "        0.0409, 0.0562, 0.0413, 0.0635, 0.1216, 0.1015, 0.0515, 0.0326, 0.0418,\n",
      "        0.0311, 0.0190, 0.0243, 0.0409, 0.0333, 0.0182, 0.0130, 0.0191, 0.0250,\n",
      "        0.0179, 0.0268, 0.0505, 0.0658, 0.0349, 0.0230, 0.0321, 0.0250, 0.0169,\n",
      "        0.0235, 0.0430, 0.0562, 0.0331, 0.0256, 0.0418, 0.0568, 0.0440, 0.0690,\n",
      "        0.1359, 0.1089, 0.0549, 0.0346, 0.0440, 0.0326, 0.0196, 0.0249, 0.0413,\n",
      "        0.0328, 0.0177, 0.0124, 0.0179, 0.0230, 0.0161, 0.0239, 0.0444, 0.0362,\n",
      "        0.0189, 0.0124, 0.0169, 0.0130, 0.0086, 0.0117, 0.0210, 0.0266, 0.0154,\n",
      "        0.0118, 0.0190, 0.0256, 0.0196, 0.0305, 0.0597, 0.0748, 0.0386, 0.0249,\n",
      "        0.0331, 0.0243, 0.0154, 0.0203, 0.0358, 0.0278, 0.0158, 0.0117, 0.0182,\n",
      "        0.0235, 0.0177, 0.0269, 0.0524, 0.0648, 0.0352, 0.0239, 0.0349, 0.0268,\n",
      "        0.0189, 0.0269, 0.0510, 0.0635, 0.0386, 0.0305, 0.0515, 0.0690, 0.0549,\n",
      "        0.0866, 0.1736, 0.1736, 0.0866, 0.0549, 0.0690, 0.0515, 0.0305, 0.0386,\n",
      "        0.0635, 0.0510, 0.0269, 0.0189, 0.0268, 0.0349, 0.0239, 0.0352, 0.0648,\n",
      "        0.0524, 0.0269, 0.0177, 0.0235, 0.0182, 0.0117, 0.0158, 0.0278, 0.0358,\n",
      "        0.0203, 0.0154, 0.0243, 0.0331, 0.0249, 0.0386, 0.0748, 0.0597, 0.0305,\n",
      "        0.0196, 0.0256, 0.0190, 0.0118, 0.0154, 0.0266, 0.0210, 0.0117, 0.0086,\n",
      "        0.0130, 0.0169, 0.0124, 0.0189, 0.0362, 0.0444, 0.0239, 0.0161, 0.0230,\n",
      "        0.0179, 0.0124, 0.0177, 0.0328, 0.0413, 0.0249, 0.0196, 0.0326, 0.0440,\n",
      "        0.0346, 0.0549, 0.1089, 0.1359, 0.0690, 0.0440, 0.0568, 0.0418, 0.0256,\n",
      "        0.0331, 0.0562, 0.0430, 0.0235, 0.0169, 0.0250, 0.0321, 0.0230, 0.0349,\n",
      "        0.0658, 0.0505, 0.0268, 0.0179, 0.0250, 0.0191, 0.0130, 0.0182, 0.0333,\n",
      "        0.0409, 0.0243, 0.0190, 0.0311, 0.0418, 0.0326, 0.0515, 0.1015, 0.1216,\n",
      "        0.0635, 0.0413, 0.0562, 0.0409, 0.0266, 0.0358, 0.0639, 0.0483, 0.0278,\n",
      "        0.0210, 0.0333, 0.0430, 0.0328, 0.0510, 0.0996, 0.1175, 0.0648, 0.0444,\n",
      "        0.0658, 0.0505, 0.0362, 0.0524, 0.0996, 0.1216, 0.0748, 0.0597, 0.1015,\n",
      "        0.1359, 0.1089, 0.1736, 0.3488], grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "modulus = torch.abs(psi_predicted)\n",
    "print(modulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diffs = modulus - torch.abs(psi_true)\n",
    "diffs = diffs.cpu().detach().numpy()\n",
    "diffs_df = pd.DataFrame(diffs)\n",
    "diffs_df.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite a few outliers, it seems that the amplitude difference between the predictions and true values is small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.018714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.110244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.004827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.013065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.061172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  256.000000\n",
       "mean     0.005856\n",
       "std      0.018714\n",
       "min     -0.110244\n",
       "25%     -0.000508\n",
       "50%      0.004827\n",
       "75%      0.013065\n",
       "max      0.061172"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the phase difference global?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4192,  4.3314,  4.0944, -0.4203,  4.1366, -0.4218, -0.4210,  4.0033,\n",
      "         4.1169, -0.4213, -0.4216,  3.7926, -0.4210,  3.3842,  3.6254, -0.4211,\n",
      "         4.1169, -0.4218, -0.4213,  4.0474, -0.4208,  3.2110,  3.8933, -0.4209,\n",
      "        -0.4208,  3.9357,  3.5997, -0.4210,  4.2730, -0.4218, -0.4215,  4.0033,\n",
      "         4.1366, -0.4221, -0.4217,  3.8235, -0.4207,  3.1245,  4.1523, -0.4210,\n",
      "        -0.4208,  3.4278,  3.5756, -0.4219,  4.0039, -0.4222, -0.4218,  3.7926,\n",
      "        -0.4210,  3.5263,  3.9976, -0.4202,  4.0039, -0.4219, -0.4212,  4.0474,\n",
      "         4.2730, -0.4207, -0.4220,  3.8235, -0.4203,  3.4320,  3.5781, -0.4203,\n",
      "         4.0944, -0.4225, -0.4221,  3.4320, -0.4217,  2.6308,  3.5814, -0.4218,\n",
      "        -0.4213,  3.2201,  3.1686, -0.4222,  3.9976, -0.4219, -0.4221,  3.3842,\n",
      "        -0.4216,  2.9189,  3.1686, -0.4219,  3.5756, -0.4226, -0.4222,  3.2110,\n",
      "         3.5997, -0.4221, -0.4230,  3.1245, -0.4220,  2.6308,  2.7744, -0.4218,\n",
      "        -0.4210,  3.1608,  3.5814, -0.4207,  4.1523, -0.4221, -0.4205,  3.9357,\n",
      "         3.8933, -0.4221, -0.4222,  3.4278, -0.4212,  3.2201,  2.9472, -0.4213,\n",
      "         3.6254, -0.4224, -0.4221,  3.5263, -0.4218,  2.9189,  2.9472, -0.4218,\n",
      "        -0.4215,  3.1608,  2.7744, -0.4221,  3.5781, -0.4225, -0.4223,  4.3314,\n",
      "         4.3314, -0.4223, -0.4225,  3.5781, -0.4221,  2.7744,  3.1608, -0.4215,\n",
      "        -0.4218,  2.9472,  2.9189, -0.4218,  3.5263, -0.4221, -0.4224,  3.6254,\n",
      "        -0.4213,  2.9472,  3.2201, -0.4212,  3.4278, -0.4222, -0.4221,  3.8933,\n",
      "         3.9357, -0.4205, -0.4221,  4.1522, -0.4207,  3.5814,  3.1608, -0.4210,\n",
      "        -0.4218,  2.7744,  2.6308, -0.4220,  3.1245, -0.4230, -0.4221,  3.5997,\n",
      "         3.2110, -0.4222, -0.4226,  3.5756, -0.4219,  3.1686,  2.9189, -0.4216,\n",
      "         3.3842, -0.4221, -0.4219,  3.9976, -0.4222,  3.1686,  3.2201, -0.4213,\n",
      "        -0.4218,  3.5814,  2.6308, -0.4217,  3.4320, -0.4221, -0.4225,  4.0944,\n",
      "        -0.4203,  3.5781,  3.4320, -0.4203,  3.8235, -0.4220, -0.4207,  4.2730,\n",
      "         4.0474, -0.4212, -0.4219,  4.0039, -0.4202,  3.9976,  3.5263, -0.4210,\n",
      "         3.7926, -0.4218, -0.4222,  4.0039, -0.4219,  3.5756,  3.4278, -0.4208,\n",
      "        -0.4210,  4.1522,  3.1245, -0.4207,  3.8235, -0.4217, -0.4221,  4.1366,\n",
      "         4.0033, -0.4215, -0.4218,  4.2730, -0.4210,  3.5997,  3.9357, -0.4208,\n",
      "        -0.4209,  3.8933,  3.2110, -0.4208,  4.0474, -0.4213, -0.4218,  4.1169,\n",
      "        -0.4211,  3.6254,  3.3842, -0.4210,  3.7926, -0.4216, -0.4213,  4.1169,\n",
      "         4.0033, -0.4210, -0.4218,  4.1366, -0.4203,  4.0944,  4.3314, -0.4192],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "phase_true = torch.angle(psi_true)\n",
    "phase_predicted = torch.angle(psi_predicted)\n",
    "\n",
    "phase_difference = phase_true - phase_predicted\n",
    "print(phase_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase differences are not global.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: tensor(0.0028-0.0038j, dtype=torch.complex128, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mse = torch.mean((psi_predicted - psi_true) ** 2)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3186,  0.1420],\n",
      "        [ 0.0645, -0.1612],\n",
      "        [ 0.0631, -0.0888],\n",
      "        [ 0.1241,  0.0555],\n",
      "        [ 0.0553, -0.0851],\n",
      "        [ 0.0545,  0.0245],\n",
      "        [ 0.0683,  0.0306],\n",
      "        [ 0.0792, -0.0923],\n",
      "        [ 0.0559, -0.0825],\n",
      "        [ 0.0478,  0.0214],\n",
      "        [ 0.0330,  0.0148],\n",
      "        [ 0.0402, -0.0306],\n",
      "        [ 0.0600,  0.0269],\n",
      "        [ 0.0431, -0.0107],\n",
      "        [ 0.0574, -0.0302],\n",
      "        [ 0.1073,  0.0480],\n",
      "        [ 0.0559, -0.0825],\n",
      "        [ 0.0465,  0.0209],\n",
      "        [ 0.0300,  0.0134],\n",
      "        [ 0.0265, -0.0338],\n",
      "        [ 0.0304,  0.0136],\n",
      "        [ 0.0209, -0.0015],\n",
      "        [ 0.0203, -0.0190],\n",
      "        [ 0.0441,  0.0197],\n",
      "        [ 0.0583,  0.0261],\n",
      "        [ 0.0251, -0.0255],\n",
      "        [ 0.0239, -0.0118],\n",
      "        [ 0.0373,  0.0167],\n",
      "        [ 0.0239, -0.0509],\n",
      "        [ 0.0377,  0.0169],\n",
      "        [ 0.0579,  0.0260],\n",
      "        [ 0.0792, -0.0923],\n",
      "        [ 0.0553, -0.0851],\n",
      "        [ 0.0470,  0.0211],\n",
      "        [ 0.0298,  0.0134],\n",
      "        [ 0.0325, -0.0263],\n",
      "        [ 0.0284,  0.0127],\n",
      "        [ 0.0190,  0.0003],\n",
      "        [ 0.0129, -0.0205],\n",
      "        [ 0.0373,  0.0167],\n",
      "        [ 0.0304,  0.0136],\n",
      "        [ 0.0174, -0.0051],\n",
      "        [ 0.0118, -0.0055],\n",
      "        [ 0.0175,  0.0078],\n",
      "        [ 0.0162, -0.0190],\n",
      "        [ 0.0163,  0.0073],\n",
      "        [ 0.0244,  0.0110],\n",
      "        [ 0.0402, -0.0306],\n",
      "        [ 0.0600,  0.0269],\n",
      "        [ 0.0323, -0.0131],\n",
      "        [ 0.0151, -0.0174],\n",
      "        [ 0.0293,  0.0131],\n",
      "        [ 0.0162, -0.0190],\n",
      "        [ 0.0154,  0.0069],\n",
      "        [ 0.0214,  0.0096],\n",
      "        [ 0.0265, -0.0338],\n",
      "        [ 0.0239, -0.0509],\n",
      "        [ 0.0303,  0.0135],\n",
      "        [ 0.0233,  0.0105],\n",
      "        [ 0.0325, -0.0263],\n",
      "        [ 0.0519,  0.0232],\n",
      "        [ 0.0421, -0.0126],\n",
      "        [ 0.0625, -0.0291],\n",
      "        [ 0.1241,  0.0555],\n",
      "        [ 0.0631, -0.0888],\n",
      "        [ 0.0501,  0.0225],\n",
      "        [ 0.0316,  0.0142],\n",
      "        [ 0.0421, -0.0126],\n",
      "        [ 0.0298,  0.0134],\n",
      "        [ 0.0171,  0.0096],\n",
      "        [ 0.0225, -0.0106],\n",
      "        [ 0.0377,  0.0169],\n",
      "        [ 0.0300,  0.0134],\n",
      "        [ 0.0176, -0.0014],\n",
      "        [ 0.0124, -0.0003],\n",
      "        [ 0.0163,  0.0073],\n",
      "        [ 0.0151, -0.0174],\n",
      "        [ 0.0147,  0.0066],\n",
      "        [ 0.0218,  0.0098],\n",
      "        [ 0.0431, -0.0107],\n",
      "        [ 0.0330,  0.0148],\n",
      "        [ 0.0185,  0.0042],\n",
      "        [ 0.0124, -0.0003],\n",
      "        [ 0.0154,  0.0069],\n",
      "        [ 0.0118, -0.0055],\n",
      "        [ 0.0078,  0.0035],\n",
      "        [ 0.0106,  0.0048],\n",
      "        [ 0.0209, -0.0015],\n",
      "        [ 0.0239, -0.0118],\n",
      "        [ 0.0141,  0.0063],\n",
      "        [ 0.0108,  0.0048],\n",
      "        [ 0.0190,  0.0003],\n",
      "        [ 0.0233,  0.0105],\n",
      "        [ 0.0171,  0.0096],\n",
      "        [ 0.0284,  0.0109],\n",
      "        [ 0.0545,  0.0245],\n",
      "        [ 0.0683,  0.0306],\n",
      "        [ 0.0386, -0.0007],\n",
      "        [ 0.0225, -0.0106],\n",
      "        [ 0.0303,  0.0135],\n",
      "        [ 0.0129, -0.0205],\n",
      "        [ 0.0141,  0.0063],\n",
      "        [ 0.0185,  0.0083],\n",
      "        [ 0.0251, -0.0255],\n",
      "        [ 0.0203, -0.0190],\n",
      "        [ 0.0144,  0.0065],\n",
      "        [ 0.0106,  0.0048],\n",
      "        [ 0.0174, -0.0051],\n",
      "        [ 0.0214,  0.0096],\n",
      "        [ 0.0176, -0.0014],\n",
      "        [ 0.0264,  0.0052],\n",
      "        [ 0.0478,  0.0214],\n",
      "        [ 0.0574, -0.0302],\n",
      "        [ 0.0321,  0.0144],\n",
      "        [ 0.0218,  0.0098],\n",
      "        [ 0.0323, -0.0131],\n",
      "        [ 0.0244,  0.0110],\n",
      "        [ 0.0185,  0.0042],\n",
      "        [ 0.0264,  0.0052],\n",
      "        [ 0.0465,  0.0209],\n",
      "        [ 0.0579,  0.0260],\n",
      "        [ 0.0386, -0.0007],\n",
      "        [ 0.0284,  0.0109],\n",
      "        [ 0.0470,  0.0211],\n",
      "        [ 0.0625, -0.0291],\n",
      "        [ 0.0501,  0.0225],\n",
      "        [ 0.0790,  0.0355],\n",
      "        [ 0.0645, -0.1612],\n",
      "        [ 0.0645, -0.1612],\n",
      "        [ 0.0790,  0.0355],\n",
      "        [ 0.0501,  0.0225],\n",
      "        [ 0.0625, -0.0291],\n",
      "        [ 0.0470,  0.0211],\n",
      "        [ 0.0284,  0.0109],\n",
      "        [ 0.0386, -0.0007],\n",
      "        [ 0.0579,  0.0260],\n",
      "        [ 0.0465,  0.0209],\n",
      "        [ 0.0264,  0.0052],\n",
      "        [ 0.0185,  0.0042],\n",
      "        [ 0.0244,  0.0110],\n",
      "        [ 0.0323, -0.0131],\n",
      "        [ 0.0218,  0.0098],\n",
      "        [ 0.0321,  0.0144],\n",
      "        [ 0.0574, -0.0302],\n",
      "        [ 0.0478,  0.0214],\n",
      "        [ 0.0264,  0.0052],\n",
      "        [ 0.0176, -0.0014],\n",
      "        [ 0.0214,  0.0096],\n",
      "        [ 0.0174, -0.0051],\n",
      "        [ 0.0106,  0.0048],\n",
      "        [ 0.0144,  0.0065],\n",
      "        [ 0.0203, -0.0190],\n",
      "        [ 0.0251, -0.0255],\n",
      "        [ 0.0185,  0.0083],\n",
      "        [ 0.0141,  0.0063],\n",
      "        [ 0.0129, -0.0205],\n",
      "        [ 0.0303,  0.0135],\n",
      "        [ 0.0225, -0.0106],\n",
      "        [ 0.0386, -0.0007],\n",
      "        [ 0.0683,  0.0306],\n",
      "        [ 0.0545,  0.0245],\n",
      "        [ 0.0284,  0.0109],\n",
      "        [ 0.0171,  0.0096],\n",
      "        [ 0.0233,  0.0105],\n",
      "        [ 0.0190,  0.0003],\n",
      "        [ 0.0108,  0.0048],\n",
      "        [ 0.0141,  0.0063],\n",
      "        [ 0.0239, -0.0118],\n",
      "        [ 0.0209, -0.0015],\n",
      "        [ 0.0106,  0.0048],\n",
      "        [ 0.0078,  0.0035],\n",
      "        [ 0.0118, -0.0055],\n",
      "        [ 0.0154,  0.0069],\n",
      "        [ 0.0124, -0.0003],\n",
      "        [ 0.0185,  0.0042],\n",
      "        [ 0.0330,  0.0148],\n",
      "        [ 0.0431, -0.0107],\n",
      "        [ 0.0218,  0.0098],\n",
      "        [ 0.0147,  0.0066],\n",
      "        [ 0.0151, -0.0174],\n",
      "        [ 0.0163,  0.0073],\n",
      "        [ 0.0124, -0.0003],\n",
      "        [ 0.0176, -0.0014],\n",
      "        [ 0.0300,  0.0134],\n",
      "        [ 0.0377,  0.0169],\n",
      "        [ 0.0225, -0.0106],\n",
      "        [ 0.0171,  0.0096],\n",
      "        [ 0.0298,  0.0134],\n",
      "        [ 0.0421, -0.0126],\n",
      "        [ 0.0316,  0.0142],\n",
      "        [ 0.0501,  0.0225],\n",
      "        [ 0.0631, -0.0888],\n",
      "        [ 0.1241,  0.0555],\n",
      "        [ 0.0625, -0.0291],\n",
      "        [ 0.0421, -0.0126],\n",
      "        [ 0.0519,  0.0232],\n",
      "        [ 0.0325, -0.0263],\n",
      "        [ 0.0233,  0.0105],\n",
      "        [ 0.0303,  0.0135],\n",
      "        [ 0.0239, -0.0509],\n",
      "        [ 0.0265, -0.0338],\n",
      "        [ 0.0214,  0.0096],\n",
      "        [ 0.0154,  0.0069],\n",
      "        [ 0.0162, -0.0190],\n",
      "        [ 0.0293,  0.0131],\n",
      "        [ 0.0151, -0.0174],\n",
      "        [ 0.0323, -0.0131],\n",
      "        [ 0.0600,  0.0269],\n",
      "        [ 0.0402, -0.0306],\n",
      "        [ 0.0244,  0.0110],\n",
      "        [ 0.0163,  0.0073],\n",
      "        [ 0.0162, -0.0190],\n",
      "        [ 0.0175,  0.0078],\n",
      "        [ 0.0118, -0.0055],\n",
      "        [ 0.0174, -0.0051],\n",
      "        [ 0.0304,  0.0136],\n",
      "        [ 0.0373,  0.0167],\n",
      "        [ 0.0129, -0.0205],\n",
      "        [ 0.0190,  0.0003],\n",
      "        [ 0.0284,  0.0127],\n",
      "        [ 0.0325, -0.0263],\n",
      "        [ 0.0298,  0.0134],\n",
      "        [ 0.0470,  0.0211],\n",
      "        [ 0.0553, -0.0851],\n",
      "        [ 0.0792, -0.0923],\n",
      "        [ 0.0579,  0.0260],\n",
      "        [ 0.0377,  0.0169],\n",
      "        [ 0.0239, -0.0509],\n",
      "        [ 0.0373,  0.0167],\n",
      "        [ 0.0239, -0.0118],\n",
      "        [ 0.0251, -0.0255],\n",
      "        [ 0.0583,  0.0261],\n",
      "        [ 0.0441,  0.0197],\n",
      "        [ 0.0203, -0.0190],\n",
      "        [ 0.0209, -0.0015],\n",
      "        [ 0.0304,  0.0136],\n",
      "        [ 0.0265, -0.0338],\n",
      "        [ 0.0300,  0.0134],\n",
      "        [ 0.0465,  0.0209],\n",
      "        [ 0.0559, -0.0825],\n",
      "        [ 0.1073,  0.0480],\n",
      "        [ 0.0574, -0.0302],\n",
      "        [ 0.0431, -0.0107],\n",
      "        [ 0.0600,  0.0269],\n",
      "        [ 0.0402, -0.0306],\n",
      "        [ 0.0330,  0.0148],\n",
      "        [ 0.0478,  0.0214],\n",
      "        [ 0.0559, -0.0825],\n",
      "        [ 0.0792, -0.0923],\n",
      "        [ 0.0683,  0.0306],\n",
      "        [ 0.0545,  0.0245],\n",
      "        [ 0.0553, -0.0851],\n",
      "        [ 0.1241,  0.0555],\n",
      "        [ 0.0631, -0.0888],\n",
      "        [ 0.0645, -0.1612],\n",
      "        [ 0.3186,  0.1420]], grad_fn=<ViewAsRealBackward0>)\n",
      "tensor([[ 0.4591,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0192,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0060,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [ 0.0192,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0192,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [ 0.0060,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0192,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [ 0.0113,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0110,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [-0.0128,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0221,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [ 0.0247,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [-0.0137,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.0246,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [ 0.0375,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0564,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.0274,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [ 0.0378,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [-0.0607,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [ 0.0404,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.0774,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [-0.1292,  0.0000],\n",
      "        [ 0.4591,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "real_imag = torch.view_as_real(psi_predicted)\n",
    "psi_true_real_imag = torch.view_as_real(psi_true.to(torch.complex64))\n",
    "print(real_imag)\n",
    "print(psi_true_real_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = H.full_H(param=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: tensor(0.0028, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mse = torch.mean((real_imag - psi_true_real_imag) ** 2)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "adam.zero_grad()\n",
    "mse.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to produce a computational graph provides evidence that .backward actually does full backpropagation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By user ucalyptus, from https://github.com/szagoruyko/pytorchviz/issues/41\n",
    "def resize_graph(dot, size_per_element=0.15, min_size=12):\n",
    "    \"\"\"Resize the graph according to how much content it contains.\n",
    "    Modify the graph in place.\n",
    "    \"\"\"\n",
    "    # Get the approximate number of nodes and edges\n",
    "    num_rows = len(dot.body)\n",
    "    content_size = num_rows * size_per_element\n",
    "    size = max(min_size, content_size)\n",
    "    size_str = str(size) + \",\" + str(size)\n",
    "    dot.graph_attr.update(size=size_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7cf4c0965240>"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7cf4c14c1550>"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mse_full.png'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = make_dot(\n",
    "    mse, params=dict(model.named_parameters()), show_attrs=True, show_saved=True\n",
    ")\n",
    "resize_graph(graph, 0.7)\n",
    "graph.render(\"mse_full\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
